{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\envs\\py36_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:493: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\ProgramData\\anaconda3\\envs\\py36_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:494: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\ProgramData\\anaconda3\\envs\\py36_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:495: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\ProgramData\\anaconda3\\envs\\py36_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:496: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\ProgramData\\anaconda3\\envs\\py36_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:497: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\ProgramData\\anaconda3\\envs\\py36_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:502: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5199, 310)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('C:/Users/wangkc/Desktop/胡喜风预测论文/mixed_data_0717_drop_replace_fill_100_5079.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unnamed: 0', '1', '2', '3', '4', '5', '6_x', '7', '8', '9', '10',\n",
       "       '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21',\n",
       "       '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32',\n",
       "       '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43',\n",
       "       '44', '45', '46', '47', '48', '49', '50', '51_x', '52', '53', '54',\n",
       "       '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65',\n",
       "       '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76',\n",
       "       '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87_x',\n",
       "       '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98',\n",
       "       '99', '100', '101', '102', '103', '104', '105', '106', '107',\n",
       "       '108', '109', '110', '111', '112', '113', '114', '115', '116_x',\n",
       "       '117', '118', '119', '120', '121', '122', '123', '124', '125',\n",
       "       '126', '127', '128', '129', '130', '131', '132', '133', '134',\n",
       "       '135', '136', '137', '138', '139', '140', '141', '142', '143',\n",
       "       '144', '145', '146', '147', '148', '149', '150', '151', '152',\n",
       "       '153', '154', '155', '156', '157', '158', '159', '160', '161',\n",
       "       '162', '163', '164', '165', '166', '167', '168', '169', '170',\n",
       "       '171', '172', '173', '174', '175', '176', '177', '178', '179',\n",
       "       '180', '181', '182', '183', '184', '185', '186', '187', '188',\n",
       "       '189', '190', '191', '192', '193', '194', '195', '196', '197',\n",
       "       '198_x', '199', '200', 'Unnamed: 0.1', 'discharge_location',\n",
       "       'religion', 'marital_status', 'ethnicity', 'diagnosis', 'gender',\n",
       "       'descriptin', '644', '617', '8555', '220046', '220545', '618',\n",
       "       '430', '220546', '220603', '220624', '220645', '220050', '1522',\n",
       "       '220051', '220180', '220210', '220228', '212', '431', '432',\n",
       "       '1523', '1524', '1526', '1529', '455', '762', '470', '51_y',\n",
       "       '1535', '87_y', '1536', '1540', '1542', '198_y', '116_y', '781',\n",
       "       '8441', '8368', '225309', '8480', '225310', '225693', '226534',\n",
       "       '226537', '226540', '227429', '227457', '786', '787', '789', '793',\n",
       "       '806', '813', '814', '824', '827', '829', '833', '837', '850',\n",
       "       '851', '853', '861', '1087', '1127', '51249', '51274', '51277',\n",
       "       '51279', '51301', '50931', '50861', '50862', '50863', '50868',\n",
       "       '50878', '50882', '50893', '50912', '50954', '51006', '51221',\n",
       "       '51222', '51237', '50970', '51464', '51491', '50910', '51244',\n",
       "       '51256', '50911', '50963', '50909', '50903', '50904', '50905',\n",
       "       '50907', '51000', '50906', 'age', 'flag'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '2', '3', '4', '5', '6_x', '7', '8', '9', '10', '11', '12',\n",
       "       '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23',\n",
       "       '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34',\n",
       "       '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45',\n",
       "       '46', '47', '48', '49', '50', '51_x', '52', '53', '54', '55', '56',\n",
       "       '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67',\n",
       "       '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78',\n",
       "       '79', '80', '81', '82', '83', '84', '85', '86', '87_x', '88', '89',\n",
       "       '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100',\n",
       "       '101', '102', '103', '104', '105', '106', '107', '108', '109',\n",
       "       '110', '111', '112', '113', '114', '115', '116_x', '117', '118',\n",
       "       '119', '120', '121', '122', '123', '124', '125', '126', '127',\n",
       "       '128', '129', '130', '131', '132', '133', '134', '135', '136',\n",
       "       '137', '138', '139', '140', '141', '142', '143', '144', '145',\n",
       "       '146', '147', '148', '149', '150', '151', '152', '153', '154',\n",
       "       '155', '156', '157', '158', '159', '160', '161', '162', '163',\n",
       "       '164', '165', '166', '167', '168', '169', '170', '171', '172',\n",
       "       '173', '174', '175', '176', '177', '178', '179', '180', '181',\n",
       "       '182', '183', '184', '185', '186', '187', '188', '189', '190',\n",
       "       '191', '192', '193', '194', '195', '196', '197', '198_x', '199',\n",
       "       '200', 'discharge_location', 'religion', 'marital_status',\n",
       "       'ethnicity', 'diagnosis', 'gender', 'descriptin', '644', '617',\n",
       "       '8555', '220046', '220545', '618', '430', '220546', '220603',\n",
       "       '220624', '220645', '220050', '1522', '220051', '220180', '220210',\n",
       "       '220228', '212', '431', '432', '1523', '1524', '1526', '1529',\n",
       "       '455', '762', '470', '51_y', '1535', '87_y', '1536', '1540',\n",
       "       '1542', '198_y', '116_y', '781', '8441', '8368', '225309', '8480',\n",
       "       '225310', '225693', '226534', '226537', '226540', '227429',\n",
       "       '227457', '786', '787', '789', '793', '806', '813', '814', '824',\n",
       "       '827', '829', '833', '837', '850', '851', '853', '861', '1087',\n",
       "       '1127', '51249', '51274', '51277', '51279', '51301', '50931',\n",
       "       '50861', '50862', '50863', '50868', '50878', '50882', '50893',\n",
       "       '50912', '50954', '51006', '51221', '51222', '51237', '50970',\n",
       "       '51464', '51491', '50910', '51244', '51256', '50911', '50963',\n",
       "       '50909', '50903', '50904', '50905', '50907', '51000', '50906',\n",
       "       'age', 'flag'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(labels=['Unnamed: 0', 'Unnamed: 0.1'], axis=1)\n",
    "data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5199, 308)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_structure, data_unstructure = data.iloc[:, 0:200], data.iloc[:, 200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5199, 200)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_structure.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5199, 108)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_unstructure.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_data = data_unstructure.corr()['flag'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  0.44188461,  0.34834065,  0.31095106,  0.29790541,\n",
       "        0.27268167,  0.2718151 ,  0.22905935,  0.22840715,  0.21215508,\n",
       "        0.20216547,  0.19953281,  0.18619697,  0.18439669,  0.16992431,\n",
       "        0.16440352,  0.16432356,  0.15335323,  0.14109696,  0.13949691,\n",
       "        0.12774348,  0.1271463 ,  0.11838982,  0.11299193,  0.1125567 ,\n",
       "        0.10861225,  0.1071288 ,  0.10025498,  0.09863866,  0.09458484,\n",
       "        0.09294859,  0.09262481,  0.09137232,  0.08903374,  0.08362927,\n",
       "        0.07543028,  0.07361162,  0.07360355,  0.0647498 ,  0.0627509 ,\n",
       "        0.05857573,  0.05222199,  0.05180129,  0.05133955,  0.04385232,\n",
       "        0.04211161,  0.03680885,  0.03597658,  0.03231726,  0.03117802,\n",
       "        0.02990743,  0.02118805,  0.01793353,  0.01481552,  0.00980294,\n",
       "        0.00526859,  0.0040515 ,  0.00249607,  0.00131689,  0.00101453,\n",
       "       -0.00442209, -0.00652561, -0.01491198, -0.0226915 , -0.0240744 ,\n",
       "       -0.02448223, -0.02635538, -0.02834546, -0.02946103, -0.03165345,\n",
       "       -0.03171733, -0.03414896, -0.03753092, -0.03795563, -0.03961062,\n",
       "       -0.04078438, -0.04597013, -0.05368642, -0.05778557, -0.05944319,\n",
       "       -0.06300886, -0.06446793, -0.06503558, -0.06854764, -0.06934461,\n",
       "       -0.07469666, -0.07549279, -0.08066237, -0.08301098, -0.08772217,\n",
       "       -0.09448277, -0.09965595, -0.10020189, -0.10905291, -0.11073511,\n",
       "       -0.11316227, -0.11405799, -0.12465224, -0.13460134, -0.13540862,\n",
       "       -0.15127792, -0.15433649, -0.16713406, -0.21699047, -0.23124315,\n",
       "       -0.25543088, -0.26503579, -0.32656055])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5199, 100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_unstructure_corr = data_unstructure[corr_data[(corr_data > 0.01) | (corr_data < -0.01)].index]\n",
    "data_unstructure_corr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flag</th>\n",
       "      <th>discharge_location</th>\n",
       "      <th>51006</th>\n",
       "      <th>51277</th>\n",
       "      <th>781</th>\n",
       "      <th>age</th>\n",
       "      <th>50868</th>\n",
       "      <th>644</th>\n",
       "      <th>50912</th>\n",
       "      <th>432</th>\n",
       "      <th>...</th>\n",
       "      <th>787</th>\n",
       "      <th>51279</th>\n",
       "      <th>50893</th>\n",
       "      <th>51244</th>\n",
       "      <th>51222</th>\n",
       "      <th>50882</th>\n",
       "      <th>51249</th>\n",
       "      <th>198_y</th>\n",
       "      <th>50862</th>\n",
       "      <th>87_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.46</td>\n",
       "      <td>9.3</td>\n",
       "      <td>21.90</td>\n",
       "      <td>11.2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>34.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.7</td>\n",
       "      <td>19.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.59</td>\n",
       "      <td>9.6</td>\n",
       "      <td>30.40</td>\n",
       "      <td>11.5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>35.7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.79</td>\n",
       "      <td>7.9</td>\n",
       "      <td>35.90</td>\n",
       "      <td>10.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>33.8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>29.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.66</td>\n",
       "      <td>8.4</td>\n",
       "      <td>14.00</td>\n",
       "      <td>11.5</td>\n",
       "      <td>29.0</td>\n",
       "      <td>35.1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.51</td>\n",
       "      <td>8.7</td>\n",
       "      <td>14.29</td>\n",
       "      <td>14.3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>35.1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   flag  discharge_location  51006  51277   781   age  50868  644  50912  432  \\\n",
       "0   1.0                 4.0   69.0   14.0  49.0  85.0   15.0  0.0    1.9  0.0   \n",
       "1   0.0                 0.0   18.0   16.7  19.0  67.0   15.0  0.0    1.1  0.0   \n",
       "2   0.0                 1.0   18.0   16.3  15.0  67.0   12.0  0.0    1.0  4.0   \n",
       "3   1.0                 3.0   36.0   17.9  29.0  84.0   12.0  0.0    1.0  3.0   \n",
       "4   0.0                 1.0   15.0   13.0  16.0  58.0   13.0  0.0    1.0  0.0   \n",
       "\n",
       "   ...   787  51279  50893  51244  51222  50882  51249  198_y  50862  87_y  \n",
       "0  ...  24.0   3.46    9.3  21.90   11.2   31.0   34.8   15.0    3.9  18.0  \n",
       "1  ...  24.0   3.59    9.6  30.40   11.5   25.0   35.7   15.0    3.2  19.0  \n",
       "2  ...  24.0   3.79    7.9  35.90   10.0   28.0   33.8   13.0    3.2  15.0  \n",
       "3  ...  18.0   3.66    8.4  14.00   11.5   29.0   35.1   15.0    3.0  14.0  \n",
       "4  ...  30.0   4.51    8.7  14.29   14.3   27.0   35.1   15.0    3.2  21.0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_unstructure_corr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5199, 300)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = pd.concat([data_structure,data_unstructure_corr], axis=1)\n",
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6_x</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>787</th>\n",
       "      <th>51279</th>\n",
       "      <th>50893</th>\n",
       "      <th>51244</th>\n",
       "      <th>51222</th>\n",
       "      <th>50882</th>\n",
       "      <th>51249</th>\n",
       "      <th>198_y</th>\n",
       "      <th>50862</th>\n",
       "      <th>87_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.181246</td>\n",
       "      <td>-0.171979</td>\n",
       "      <td>-0.020658</td>\n",
       "      <td>-0.286978</td>\n",
       "      <td>0.018740</td>\n",
       "      <td>0.082198</td>\n",
       "      <td>0.090863</td>\n",
       "      <td>0.136441</td>\n",
       "      <td>0.241859</td>\n",
       "      <td>0.211144</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.46</td>\n",
       "      <td>9.3</td>\n",
       "      <td>21.90</td>\n",
       "      <td>11.2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>34.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.177999</td>\n",
       "      <td>-0.171340</td>\n",
       "      <td>-0.018405</td>\n",
       "      <td>-0.279906</td>\n",
       "      <td>0.013936</td>\n",
       "      <td>0.076547</td>\n",
       "      <td>0.093037</td>\n",
       "      <td>0.130213</td>\n",
       "      <td>0.242734</td>\n",
       "      <td>0.204262</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.59</td>\n",
       "      <td>9.6</td>\n",
       "      <td>30.40</td>\n",
       "      <td>11.5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>35.7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.170776</td>\n",
       "      <td>-0.169037</td>\n",
       "      <td>-0.019629</td>\n",
       "      <td>-0.270112</td>\n",
       "      <td>0.014875</td>\n",
       "      <td>0.083863</td>\n",
       "      <td>0.088988</td>\n",
       "      <td>0.128219</td>\n",
       "      <td>0.242143</td>\n",
       "      <td>0.208636</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.79</td>\n",
       "      <td>7.9</td>\n",
       "      <td>35.90</td>\n",
       "      <td>10.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>33.8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.186937</td>\n",
       "      <td>-0.182405</td>\n",
       "      <td>-0.026913</td>\n",
       "      <td>-0.296987</td>\n",
       "      <td>0.028211</td>\n",
       "      <td>0.082213</td>\n",
       "      <td>0.100136</td>\n",
       "      <td>0.137477</td>\n",
       "      <td>0.243451</td>\n",
       "      <td>0.205574</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.66</td>\n",
       "      <td>8.4</td>\n",
       "      <td>14.00</td>\n",
       "      <td>11.5</td>\n",
       "      <td>29.0</td>\n",
       "      <td>35.1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.163789</td>\n",
       "      <td>-0.155432</td>\n",
       "      <td>-0.004861</td>\n",
       "      <td>-0.258247</td>\n",
       "      <td>-0.003251</td>\n",
       "      <td>0.074688</td>\n",
       "      <td>0.078321</td>\n",
       "      <td>0.120354</td>\n",
       "      <td>0.244487</td>\n",
       "      <td>0.214203</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.51</td>\n",
       "      <td>8.7</td>\n",
       "      <td>14.29</td>\n",
       "      <td>14.3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>35.1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5       6_x         7  \\\n",
       "0 -0.181246 -0.171979 -0.020658 -0.286978  0.018740  0.082198  0.090863   \n",
       "1 -0.177999 -0.171340 -0.018405 -0.279906  0.013936  0.076547  0.093037   \n",
       "2 -0.170776 -0.169037 -0.019629 -0.270112  0.014875  0.083863  0.088988   \n",
       "3 -0.186937 -0.182405 -0.026913 -0.296987  0.028211  0.082213  0.100136   \n",
       "4 -0.163789 -0.155432 -0.004861 -0.258247 -0.003251  0.074688  0.078321   \n",
       "\n",
       "          8         9        10  ...   787  51279  50893  51244  51222  50882  \\\n",
       "0  0.136441  0.241859  0.211144  ...  24.0   3.46    9.3  21.90   11.2   31.0   \n",
       "1  0.130213  0.242734  0.204262  ...  24.0   3.59    9.6  30.40   11.5   25.0   \n",
       "2  0.128219  0.242143  0.208636  ...  24.0   3.79    7.9  35.90   10.0   28.0   \n",
       "3  0.137477  0.243451  0.205574  ...  18.0   3.66    8.4  14.00   11.5   29.0   \n",
       "4  0.120354  0.244487  0.214203  ...  30.0   4.51    8.7  14.29   14.3   27.0   \n",
       "\n",
       "   51249  198_y  50862  87_y  \n",
       "0   34.8   15.0    3.9  18.0  \n",
       "1   35.7   15.0    3.2  19.0  \n",
       "2   33.8   13.0    3.2  15.0  \n",
       "3   35.1   15.0    3.0  14.0  \n",
       "4   35.1   15.0    3.2  21.0  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = np.array(new_data.drop(labels=['flag'], axis=1)), np.array(new_data['flag'].apply(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5199, 299)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5199,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 666, test_size = 0.33 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_structure, X_train_unstructure = X_train[:, 0:200], X_train[:, 200:]\n",
    "X_test_structure, X_test_unstructure = X_test[:, 0:200], X_test[:, 200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3483, 200)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_structure.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3483, 99)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_unstructure.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_scaler = StandardScaler()\n",
    "standard_scaler.fit(X_train_unstructure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.92276773e+00, 2.96495837e+01, 1.48659144e+01, 2.94938530e+01,\n",
       "       7.04806202e+01, 1.41410910e+01, 2.63313236e-01, 1.53306919e+00,\n",
       "       1.36713178e+00, 3.60875969e+00, 5.07258111e-01, 1.08979529e+01,\n",
       "       9.71043296e+01, 3.71498421e+00, 1.47809044e+01, 1.38102785e+00,\n",
       "       3.07332759e+01, 1.32399265e+02, 7.39322194e+01, 4.51264387e+02,\n",
       "       1.47621390e+01, 5.10340798e+00, 1.01623313e+00, 1.75101924e-01,\n",
       "       6.49038185e-02, 1.26933026e+02, 1.08484065e-01, 1.22855843e+01,\n",
       "       1.95047947e+01, 1.22967844e+01, 3.93051967e-01, 1.22751163e+01,\n",
       "       3.59665547e+02, 7.77353287e+01, 1.52384170e+04, 1.14967557e+01,\n",
       "       3.27829744e+02, 1.44291631e+02, 1.38579437e+02, 1.38365418e+02,\n",
       "       1.38028814e+02, 9.43152455e-01, 4.15067471e+00, 1.92120385e+01,\n",
       "       7.31094746e+00, 1.35886882e+02, 1.77031295e+00, 2.01042205e+00,\n",
       "       1.38360034e+02, 4.16648866e+00, 1.22400287e+02, 2.90510393e+01,\n",
       "       1.01811944e+01, 2.18291398e+02, 1.04946196e+02, 4.31105627e+01,\n",
       "       2.73993115e+00, 5.56662590e+01, 1.45464278e+02, 5.73153747e+01,\n",
       "       4.36159231e+01, 1.40700924e+02, 5.63928682e+01, 8.23428079e-01,\n",
       "       1.45300534e+02, 1.17209483e+02, 1.54853959e+02, 9.91615389e+01,\n",
       "       3.11024235e+01, 3.14450359e+01, 6.02228309e+01, 1.15352719e+02,\n",
       "       3.19377954e+01, 5.73051392e+00, 6.11076947e+01, 1.57793982e+02,\n",
       "       1.60728699e+02, 8.91366638e+01, 8.39076946e+00, 3.59409130e+00,\n",
       "       8.34460237e+00, 1.59171932e+02, 1.15746942e+02, 5.61876543e+01,\n",
       "       1.08646914e+01, 3.22682458e+01, 7.98115705e+01, 1.06151220e+01,\n",
       "       5.80802756e+01, 2.40643239e+01, 3.61699110e+00, 8.53154177e+00,\n",
       "       1.44193081e+01, 1.09052570e+01, 2.52899167e+01, 3.38227735e+01,\n",
       "       1.29007034e+01, 3.20157910e+00, 1.49531036e+01])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_scaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_unstructure_standard = standard_scaler.transform(X_train_unstructure)\n",
    "X_test_unstructure_standard = standard_scaler.transform(X_test_unstructure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3483, 99)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_unstructure_standard.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1716, 99)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_unstructure_standard.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3483, 200)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_structure.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1716, 200)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_structure.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3483,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1716,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3483, 200)\n",
      "(3483, 99)\n",
      "(3483,)\n",
      "(1716, 200)\n",
      "(1716, 99)\n",
      "(1716,)\n"
     ]
    }
   ],
   "source": [
    "class DiseaseData:\n",
    "    def __init__(self, train_model=True, need_shuffle=True):\n",
    "        if train_model:\n",
    "            self._data_structure = X_train_structure\n",
    "            self._data_unstructure = X_train_unstructure_standard\n",
    "            self._labels = y_train\n",
    "        else:\n",
    "            self._data_structure = X_test_structure\n",
    "            self._data_unstructure = X_test_unstructure_standard\n",
    "            self._labels = y_test\n",
    "        print(self._data_structure.shape)\n",
    "        print(self._data_unstructure.shape)\n",
    "        print(self._labels.shape)\n",
    "\n",
    "        self._num_examples = self._data_structure.shape[0]\n",
    "        self._need_shuffle = need_shuffle\n",
    "        self._indicator = 0\n",
    "        if self._need_shuffle:\n",
    "            self._shuffle_data()\n",
    "            \n",
    "    def _shuffle_data(self):\n",
    "        # [0,1,2,3,4,5] -> [5,3,2,4,0,1]\n",
    "        p = np.random.permutation(self._num_examples)\n",
    "        self._data_structure = self._data_structure[p]\n",
    "        self._data_unstructure = self._data_unstructure[p]\n",
    "        self._labels = self._labels[p]\n",
    "    \n",
    "    def next_batch(self, batch_size):\n",
    "        \"\"\"return batch_size examples as a batch.\"\"\"\n",
    "        end_indicator = self._indicator + batch_size\n",
    "        if end_indicator > self._num_examples:\n",
    "            if self._need_shuffle:\n",
    "                self._shuffle_data()\n",
    "                self._indicator = 0\n",
    "                end_indicator = batch_size\n",
    "            else:\n",
    "                raise Exception(\"have no more examples\")\n",
    "        if end_indicator > self._num_examples:\n",
    "            raise Exception(\"batch size is larger than all examples\")\n",
    "        batch_data_structure = self._data_structure[self._indicator: end_indicator]\n",
    "        batch_data_unstructure = self._data_unstructure[self._indicator: end_indicator]\n",
    "        batch_labels = self._labels[self._indicator: end_indicator]\n",
    "        self._indicator = end_indicator\n",
    "        return batch_data_structure, batch_data_unstructure, batch_labels\n",
    "\n",
    "train_data = DiseaseData(True, True)\n",
    "test_data = DiseaseData(False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate = 1e-3\n",
    "\n",
    "# # x1 得到 hidden1_1 结构化数据 20 * 200\n",
    "# x1 = tf.placeholder(tf.float32, [None, X_train_structure.shape[1]])\n",
    "# hidden1_1 = tf.layers.dense(x1, 100, activation=tf.nn.relu)\n",
    "\n",
    "# # x2 得到 hidden1_2 非结构化数据 20 * 99\n",
    "# x2 = tf.placeholder(tf.float32, [None, X_train_unstructure_standard.shape[1]])\n",
    "# hidden1_2 = tf.layers.dense(x2, 50, activation=tf.nn.relu)\n",
    "\n",
    "# y = tf.placeholder(tf.int64, [None])\n",
    "\n",
    "# # # hidden1_1 和 hidden1_2 拼接通过DNN得到20*10的输出 取均值后得到w 20*1\n",
    "# # hidden_concat = tf.concat([hidden1_1, hidden1_2], 1)\n",
    "# # hidden_concat_1 = tf.layers.dense(hidden_concat, 100, activation=tf.nn.relu)\n",
    "# # hidden_concat_2 = tf.layers.dense(hidden_concat_1, 100, activation=tf.nn.relu)\n",
    "# # hidden_concat_3 = tf.layers.dense(hidden_concat_2, 50, activation=tf.nn.relu)\n",
    "# # hidden_res = tf.layers.dense(hidden_concat_3, 10)\n",
    "# # w = tf.reduce_mean(hidden_res, axis=1)\n",
    "# # w = tf.reshape(w, (20, 1))\n",
    "# # # hidden1_1 = w * hidden1_1 + hidden1_1\n",
    "# # # 结果为20*100\n",
    "# # hidden1_1 = w * hidden1_1 + hidden1_1\n",
    "# # hidden1_2 = w * hidden1_2 + hidden1_2\n",
    "\n",
    "# # 结构化数据 200维\n",
    "# hidden2_1 = tf.layers.dense(hidden1_1, 50, activation=tf.nn.relu)\n",
    "# hidden3_1 = tf.layers.dense(hidden2_1, 20, activation=tf.nn.relu)\n",
    "# y_1 = tf.layers.dense(hidden3_1, 1)\n",
    "\n",
    "# # 非结构化数据 100维\n",
    "# hidden2_2 = tf.layers.dense(hidden1_2, 30, activation=tf.nn.relu)\n",
    "# hidden3_2 = tf.layers.dense(hidden2_2, 10, activation=tf.nn.relu)\n",
    "# y_2 = tf.layers.dense(hidden3_2, 1)\n",
    "\n",
    "# # 计算损失\n",
    "# # loss_1 = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=y_1)\n",
    "# # loss_2 = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=y_2)\n",
    "# p_y_1 = tf.nn.sigmoid(y_1)\n",
    "# p_y_2 = tf.nn.sigmoid(y_2)\n",
    "# y_reshaped = tf.reshape(y, (-1, 1))\n",
    "# loss_1 = tf.reduce_mean(tf.square(tf.cast(y_reshaped, tf.float32) - p_y_1))\n",
    "# loss_2 = tf.reduce_mean(tf.square(tf.cast(y_reshaped, tf.float32) - p_y_2))\n",
    "\n",
    "# # 计算准确率\n",
    "# accuracy_1 = tf.reduce_mean(tf.cast(tf.equal(tf.cast(p_y_1 > 0.5, tf.int64), y_reshaped), tf.float64))\n",
    "# accuracy_2 = tf.reduce_mean(tf.cast(tf.equal(tf.cast(p_y_2 > 0.5, tf.int64), y_reshaped), tf.float64))\n",
    "# # accuracy_1 = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(y_1, 1), y), tf.float64))\n",
    "# # accuracy_2 = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(y_2, 1), y), tf.float64))\n",
    "\n",
    "# # 选择合适的损失函数\n",
    "# loss = loss_1 * 0.5 + loss_2 * 0.5\n",
    "# accuracy = accuracy_1 * 0.5 + accuracy_2 * 0.5\n",
    "\n",
    "# with tf.name_scope('train_op'):\n",
    "#     train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-6\n",
    "\n",
    "# x2 得到 hidden1_2 非结构化数据 20 * 99\n",
    "x = tf.placeholder(tf.float32, [None, X_train_unstructure_standard.shape[1]])\n",
    "hidden1_2 = tf.layers.dense(x, 100, activation=tf.nn.sigmoid)\n",
    "\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "\n",
    "# 非结构化数据 100维\n",
    "hidden2_2 = tf.layers.dense(hidden1_2,50, activation=tf.nn.sigmoid)\n",
    "# hidden3_2 = tf.layers.dense(hidden2_2, 20, activation=tf.nn.relu)\n",
    "y_2 = tf.layers.dense(hidden2_2, 2)\n",
    "\n",
    "# 计算损失\n",
    "loss = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=y_2)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(y_2, 1), y), tf.float64))\n",
    "\n",
    "with tf.name_scope('train_op'):\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step: 500, loss: 0.64373, acc: 0.70000\n",
      "[Train] Step: 1000, loss: 0.73392, acc: 0.63000\n",
      "[Train] Step: 1500, loss: 0.58337, acc: 0.74000\n",
      "[Train] Step: 2000, loss: 0.65869, acc: 0.67000\n",
      "[Train] Step: 2500, loss: 0.54858, acc: 0.76000\n",
      "[Train] Step: 3000, loss: 0.62106, acc: 0.70000\n",
      "[Train] Step: 3500, loss: 0.66433, acc: 0.65000\n",
      "[Train] Step: 4000, loss: 0.59215, acc: 0.72000\n",
      "[Train] Step: 4500, loss: 0.57298, acc: 0.73000\n",
      "[Train] Step: 5000, loss: 0.55436, acc: 0.75000\n",
      "(1716, 200)\n",
      "(1716, 99)\n",
      "(1716,)\n",
      "[Test ] Step: 5000, acc: 0.69588\n",
      "[Train] Step: 5500, loss: 0.60814, acc: 0.69000\n",
      "[Train] Step: 6000, loss: 0.61228, acc: 0.69000\n",
      "[Train] Step: 6500, loss: 0.60008, acc: 0.70000\n",
      "[Train] Step: 7000, loss: 0.66152, acc: 0.62000\n",
      "[Train] Step: 7500, loss: 0.58820, acc: 0.70000\n",
      "[Train] Step: 8000, loss: 0.64555, acc: 0.64000\n",
      "[Train] Step: 8500, loss: 0.58565, acc: 0.70000\n",
      "[Train] Step: 9000, loss: 0.60873, acc: 0.67000\n",
      "[Train] Step: 9500, loss: 0.58788, acc: 0.69000\n",
      "[Train] Step: 10000, loss: 0.54178, acc: 0.74000\n",
      "(1716, 200)\n",
      "(1716, 99)\n",
      "(1716,)\n",
      "[Test ] Step: 10000, acc: 0.69588\n",
      "[Train] Step: 10500, loss: 0.54423, acc: 0.73000\n",
      "[Train] Step: 11000, loss: 0.53029, acc: 0.75000\n",
      "[Train] Step: 11500, loss: 0.52655, acc: 0.78000\n",
      "[Train] Step: 12000, loss: 0.53560, acc: 0.75000\n",
      "[Train] Step: 12500, loss: 0.60418, acc: 0.67000\n",
      "[Train] Step: 13000, loss: 0.60121, acc: 0.66000\n",
      "[Train] Step: 13500, loss: 0.48880, acc: 0.78000\n",
      "[Train] Step: 14000, loss: 0.60540, acc: 0.66000\n",
      "[Train] Step: 14500, loss: 0.51223, acc: 0.76000\n",
      "[Train] Step: 15000, loss: 0.55171, acc: 0.71000\n",
      "(1716, 200)\n",
      "(1716, 99)\n",
      "(1716,)\n",
      "[Test ] Step: 15000, acc: 0.69588\n",
      "[Train] Step: 15500, loss: 0.54282, acc: 0.72000\n",
      "[Train] Step: 16000, loss: 0.60637, acc: 0.63000\n",
      "[Train] Step: 16500, loss: 0.58731, acc: 0.69000\n",
      "[Train] Step: 17000, loss: 0.50999, acc: 0.74000\n",
      "[Train] Step: 17500, loss: 0.52364, acc: 0.74000\n",
      "[Train] Step: 18000, loss: 0.47989, acc: 0.78000\n",
      "[Train] Step: 18500, loss: 0.54612, acc: 0.71000\n",
      "[Train] Step: 19000, loss: 0.51957, acc: 0.71000\n",
      "[Train] Step: 19500, loss: 0.51411, acc: 0.74000\n",
      "[Train] Step: 20000, loss: 0.55525, acc: 0.69000\n",
      "(1716, 200)\n",
      "(1716, 99)\n",
      "(1716,)\n",
      "[Test ] Step: 20000, acc: 0.70000\n",
      "[Train] Step: 20500, loss: 0.55956, acc: 0.70000\n",
      "[Train] Step: 21000, loss: 0.50367, acc: 0.74000\n",
      "[Train] Step: 21500, loss: 0.44068, acc: 0.84000\n",
      "[Train] Step: 22000, loss: 0.48940, acc: 0.77000\n",
      "[Train] Step: 22500, loss: 0.54919, acc: 0.71000\n",
      "[Train] Step: 23000, loss: 0.46507, acc: 0.76000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-0ea487540f42>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mbatch_data_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_data_unstructure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         loss_val, acc_val, _ = sess.run(\n\u001b[0;32m     11\u001b[0m             \u001b[1;33m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-de1ad16c8bb3>\u001b[0m in \u001b[0;36mnext_batch\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend_indicator\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_examples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_need_shuffle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shuffle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_indicator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m                 \u001b[0mend_indicator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-de1ad16c8bb3>\u001b[0m in \u001b[0;36m_shuffle_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_examples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_structure\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_structure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_unstructure\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_unstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "batch_size = 100\n",
    "train_steps = 100000\n",
    "test_steps = 17\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(train_steps):\n",
    "        batch_data_structure, batch_data_unstructure, batch_labels = train_data.next_batch(batch_size)\n",
    "        loss_val, acc_val, _ = sess.run(\n",
    "            [loss, accuracy, train_op],\n",
    "            feed_dict={\n",
    "#                 x1: batch_data_structure,\n",
    "                x: batch_data_unstructure,\n",
    "                y: batch_labels})\n",
    "        if (i+1) % 500 == 0:\n",
    "            print('[Train] Step: %d, loss: %4.5f, acc: %4.5f' \n",
    "                  % (i+1, loss_val, acc_val))\n",
    "        if (i+1) % 5000 == 0:\n",
    "            test_data = DiseaseData(False, False)\n",
    "            all_test_acc_val = []\n",
    "            for j in range(test_steps):\n",
    "                test_batch_data_structure, test_batch_data_unstructure, test_batch_labels \\\n",
    "                    = test_data.next_batch(batch_size)\n",
    "                test_acc_val = sess.run(\n",
    "                    [accuracy],\n",
    "                    feed_dict = {\n",
    "#                         x1: test_batch_data_structure, \n",
    "                        x: test_batch_data_unstructure, \n",
    "                        y: test_batch_labels\n",
    "                    })\n",
    "                all_test_acc_val.append(test_acc_val)\n",
    "            print('[Test ] Step: %d, acc: %4.5f'\n",
    "                  % (i+1, np.mean(all_test_acc_val)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6_cpu",
   "language": "python",
   "name": "py36_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
