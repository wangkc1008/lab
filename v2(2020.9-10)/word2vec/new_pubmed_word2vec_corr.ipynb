{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_path = 'D:/迅雷下载/wikipedia-pubmed-and-PMC-w2v.bin'\n",
    "word2vec = gensim.models.KeyedVectors.load_word2vec_format(embedding_path,binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Found %s word vectors of word2vec' % len(word2vec.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word2vec['heart'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'C:/Users/wangkc/Desktop/胡喜风预测论文/text_flag_20200912.csv'\n",
    "data = pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = data[['hadm_id', 'text']].values\n",
    "text[0, 0]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_list = []\n",
    "for hadm_id, item in text:\n",
    "    new_text = re.sub('\\[[^\\[\\]]*\\]', ' ', item)\n",
    "    new_text = re.sub('[#$%&\\'()*+,-./:;<=>?@，。?★、…【】《》？“”！[\\\\]^_`{|}~\\s]+', \" \", new_text)\n",
    "    new_text = new_text.replace('\\r\\n', ' ').replace('\\n', ' ').replace('\\r', ' ').split(' ')\n",
    "    new_text = list(filter(None, new_text))\n",
    "    res_list.append([hadm_id, new_text])\n",
    "len(res_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_data = []\n",
    "for item in res_list: \n",
    "    res = np.zeros(200)\n",
    "    num = 0\n",
    "    none_num = 0\n",
    "    for word in item[1]:\n",
    "        if word in word2vec.wv.vocab:\n",
    "            res += word2vec[word]\n",
    "            num += 1\n",
    "        elif word.lower() in word2vec.wv.vocab:\n",
    "            print('lower: ', item[0], word)\n",
    "            res += word2vec[word.lower()]\n",
    "            num += 1\n",
    "        elif word.upper() in word2vec.wv.vocab:\n",
    "            print('upper: ', item[0], word)\n",
    "            res += word2vec[word.upper()]\n",
    "            num += 1\n",
    "        else:\n",
    "#             print(item[0], word)\n",
    "            none_num += 1\n",
    "    print('总数', item[0], num)\n",
    "    print('None总数', item[0], none_num)\n",
    "    vocab_data.append(np.append(item[0], res / num))\n",
    "vocab_data = np.array(vocab_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocab_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_pd = pd.DataFrame(vocab_data)\n",
    "vocab_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_pd['hadm_id'] = [int(item) for item in vocab_pd[0].values]\n",
    "vocab_pd = vocab_pd.drop(labels=[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = pd.merge(vocab_pd, data[['hadm_id', 'flag']], on='hadm_id', how='left')\n",
    "total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = total_data.drop(labels=['hadm_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data.corr()['flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = total_data.corr()\n",
    "expire_flag = corr['flag'].sort_values(ascending=False)\n",
    "expire_flag[((expire_flag > 0.1) | (expire_flag < -0.1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_data = total_data[expire_flag[(expire_flag > 0) | (expire_flag < 0)].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = np.array(corr_data.drop(labels=['flag'], axis=1)), np.array([int(item) for item in corr_data['flag']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=666,test_size = 0.33 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = StandardScaler()\n",
    "standard_scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_standard = standard_scaler.transform(X_train)\n",
    "X_test_standard = standard_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=1000,random_state=666)\n",
    "lr.fit(X_train_standard,y_train)\n",
    "lr.score(X_test_standard,y_test) # 输出一个正确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = SVC()\n",
    "clf.fit(X_train_standard,y_train)\n",
    "predictions = clf.predict(X_test_standard)\n",
    "print(\"SVM\")\n",
    "print(classification_report(y_test,predictions))\n",
    "print(\"AC\",accuracy_score(y_test,predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6_cpu",
   "language": "python",
   "name": "py36_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
