{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[easydl] tensorflow not available!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from itertools import product\n",
    "from collections import OrderedDict, namedtuple\n",
    "from easydl import clear_output\n",
    "from IPython.display import display\n",
    "import torch.utils.data as Data\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原数据size (1132, 816)\n",
      "原数据X_size:(1132, 815), y_size:(1132,)\n",
      "原数据y分布 Counter({0: 876, 1: 256})\n",
      "文本数据 (1132, 768)\n",
      "数值数据 (1132, 10)\n",
      "分割后X_size:(1132, 778), y_size:(1132,)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('E:/hxf_prediction/data_mimic/hxf/mimic0710/hxf/SelfData/data/total_data_xinjiao_20210125.csv', encoding='utf-8')\n",
    "print('原数据size', data.shape)\n",
    "X, y = np.array(data.drop(labels=['label'], axis=1)), np.array(data['label'].apply(int))\n",
    "print('原数据X_size:%s, y_size:%s' % (X.shape, y.shape))\n",
    "print('原数据y分布', Counter(y))\n",
    "X_text, X_digital = X[:, 0:768], X[:, 805:]\n",
    "flag = 'feature_5'\n",
    "print('文本数据', X_text.shape)\n",
    "print('数值数据', X_digital.shape)\n",
    "X_sub = np.hstack((X_text, X_digital))\n",
    "print('分割后X_size:%s, y_size:%s' % (X_sub.shape, y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "插值后y分布 Counter({0: 876, 1: 876})\n"
     ]
    }
   ],
   "source": [
    "SMO = SMOTE(random_state=666)\n",
    "X_res,y_res = SMO.fit_resample(X_sub,y)\n",
    "print('插值后y分布', Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, text_in_features, digital_in_features):\n",
    "        super(Network, self).__init__()\n",
    "        self.bn_text = nn.BatchNorm1d(text_in_features)\n",
    "        self.bn_digital = nn.BatchNorm1d(digital_in_features)\n",
    "        self.fc_text_1 = nn.Linear(in_features=text_in_features, out_features=128)\n",
    "        self.fc_digital_1 = nn.Linear(in_features=digital_in_features, out_features=64)\n",
    "        self.fc_connect_1 = nn.Linear(in_features=192, out_features=256)\n",
    "        self.fc_connect_2 = nn.Linear(in_features=256, out_features=128)\n",
    "        self.fc_connect_3 = nn.Linear(in_features=128, out_features=64)\n",
    "        self.fc_connect_4 = nn.Linear(in_features=64, out_features=2)\n",
    "\n",
    "    def forward(self, text_input, digital_input):\n",
    "        text_input_bn = self.bn_text(text_input)\n",
    "        text_1 = self.fc_text_1(text_input_bn)\n",
    "        text_1 = F.softsign(text_1)\n",
    "        \n",
    "        digital_input_bn = self.bn_digital(digital_input)\n",
    "        digital_1 = self.fc_digital_1(digital_input_bn)\n",
    "        digital_1 = F.tanh(digital_1)\n",
    "\n",
    "        t_d_connect = torch.cat([text_1, digital_1], 1)\n",
    "        t_d_connect = F.tanh(self.fc_connect_1(t_d_connect))\n",
    "        t_d_connect = F.tanh(self.fc_connect_2(t_d_connect))\n",
    "        t_d_connect = F.tanh(self.fc_connect_3(t_d_connect))\n",
    "        t_d_connect = nn.Dropout(p=0.5)(t_d_connect)\n",
    "        t_d_connect = self.fc_connect_4(t_d_connect)\n",
    "        return t_d_connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "def save_result(model, run_data):\n",
    "    \"\"\"\n",
    "    运行结果保存\n",
    "        默认文件路径 ./run_data\n",
    "        默认模型路径 ./model\n",
    "    :param model: 模型\n",
    "    :param run_data: 运行数据\n",
    "    \"\"\"\n",
    "    result_dir = './run_data'\n",
    "    model_dir = './model'\n",
    "    name = 'result'\n",
    "    \n",
    "    if not os.path.exists(result_dir):\n",
    "        os.mkdir(result_dir)\n",
    "        \n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "    \n",
    "    time_index = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    # 保存运行文件\n",
    "    run_data_path = os.path.join(result_dir, name)\n",
    "    pd.DataFrame(run_data).to_csv(f'{run_data_path}_{time_index}.csv', index=False)\n",
    "    with open(f'{run_data_path}_{time_index}.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(run_data, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    # 保存运行模型\n",
    "    model_path = os.path.join(model_dir, name)\n",
    "    torch.save(model.state_dict(), f'{model_path}_{time_index}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunBuilder:\n",
    "    @staticmethod\n",
    "    def get_run(params):  # 静态方法，不需要实例化\n",
    "\n",
    "        Run = namedtuple('Run', params.keys())\n",
    "        runs = []\n",
    "        for v in product(*params.values()):\n",
    "            runs.append(Run(*v))\n",
    "\n",
    "        return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1226, 778) (526, 778) (1226,) (526,)\n"
     ]
    }
   ],
   "source": [
    "train_params = OrderedDict(\n",
    "    lr = [.01, .001],\n",
    "    batch_size = [50, 100],\n",
    "    shuffle = [False]\n",
    "#     device = ['cuda'],\n",
    "#     num_workers = [1]  # 有多少子进程被用来加载数据 默认为0即在主进程中加载数据 可以利用多核CPU的特点指定num_workers个数 提前将数据加载到内存中\n",
    ")\n",
    "\n",
    "test_params = OrderedDict(\n",
    "    lr = [np.nan],\n",
    "    batch_size = [50],\n",
    "    shuffle = [False]\n",
    "#     device = ['cuda'],\n",
    "#     num_workers = [1]  # 有多少子进程被用来加载数据 默认为0即在主进程中加载数据 可以利用多核CPU的特点指定num_workers个数 提前将数据加载到内存中\n",
    ")\n",
    "num_workers = 1\n",
    "device = 'cuda'\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.3, random_state=np.random.seed())\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flag</th>\n",
       "      <th>current</th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "      <th>epoch_duration</th>\n",
       "      <th>run_duration</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>shuffle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>feature_5</td>\n",
       "      <td>Train</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.757145</td>\n",
       "      <td>0.491843</td>\n",
       "      <td>0.497676</td>\n",
       "      <td>0.528847</td>\n",
       "      <td>0.502497</td>\n",
       "      <td>0.488002</td>\n",
       "      <td>8.442451</td>\n",
       "      <td>8.468382</td>\n",
       "      <td>0.010</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feature_5</td>\n",
       "      <td>Train</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.717341</td>\n",
       "      <td>0.531811</td>\n",
       "      <td>0.539937</td>\n",
       "      <td>0.563606</td>\n",
       "      <td>0.542589</td>\n",
       "      <td>0.536895</td>\n",
       "      <td>0.711098</td>\n",
       "      <td>9.604316</td>\n",
       "      <td>0.010</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>feature_5</td>\n",
       "      <td>Train</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.699180</td>\n",
       "      <td>0.570147</td>\n",
       "      <td>0.572026</td>\n",
       "      <td>0.609985</td>\n",
       "      <td>0.582605</td>\n",
       "      <td>0.573741</td>\n",
       "      <td>1.050193</td>\n",
       "      <td>10.842008</td>\n",
       "      <td>0.010</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feature_5</td>\n",
       "      <td>Train</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.714798</td>\n",
       "      <td>0.576672</td>\n",
       "      <td>0.578434</td>\n",
       "      <td>0.624680</td>\n",
       "      <td>0.594105</td>\n",
       "      <td>0.578917</td>\n",
       "      <td>0.850754</td>\n",
       "      <td>11.884248</td>\n",
       "      <td>0.010</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feature_5</td>\n",
       "      <td>Test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.724999</td>\n",
       "      <td>0.566540</td>\n",
       "      <td>0.541953</td>\n",
       "      <td>0.569294</td>\n",
       "      <td>0.551174</td>\n",
       "      <td>0.570118</td>\n",
       "      <td>0.714062</td>\n",
       "      <td>12.792791</td>\n",
       "      <td>0.010</td>\n",
       "      <td>50-50</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>feature_5</td>\n",
       "      <td>Train</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>0.109815</td>\n",
       "      <td>0.962480</td>\n",
       "      <td>0.954530</td>\n",
       "      <td>0.968461</td>\n",
       "      <td>0.961206</td>\n",
       "      <td>0.962539</td>\n",
       "      <td>0.607348</td>\n",
       "      <td>16.632527</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>feature_5</td>\n",
       "      <td>Train</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>0.041969</td>\n",
       "      <td>0.984502</td>\n",
       "      <td>0.987466</td>\n",
       "      <td>0.985556</td>\n",
       "      <td>0.986336</td>\n",
       "      <td>0.985014</td>\n",
       "      <td>0.709105</td>\n",
       "      <td>17.558052</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>feature_5</td>\n",
       "      <td>Train</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>0.048390</td>\n",
       "      <td>0.984502</td>\n",
       "      <td>0.987265</td>\n",
       "      <td>0.985863</td>\n",
       "      <td>0.986397</td>\n",
       "      <td>0.985297</td>\n",
       "      <td>0.602416</td>\n",
       "      <td>18.345972</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>feature_5</td>\n",
       "      <td>Train</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.056569</td>\n",
       "      <td>0.980424</td>\n",
       "      <td>0.980092</td>\n",
       "      <td>0.983322</td>\n",
       "      <td>0.981591</td>\n",
       "      <td>0.981391</td>\n",
       "      <td>0.621339</td>\n",
       "      <td>19.152788</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>feature_5</td>\n",
       "      <td>Test</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.934041</td>\n",
       "      <td>0.802281</td>\n",
       "      <td>0.732325</td>\n",
       "      <td>0.910106</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>0.804067</td>\n",
       "      <td>0.561498</td>\n",
       "      <td>19.892809</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100-50</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         flag current  run  epoch      loss  accuracy  precision    recall  \\\n",
       "0   feature_5   Train    1      1  0.757145  0.491843   0.497676  0.528847   \n",
       "1   feature_5   Train    1      2  0.717341  0.531811   0.539937  0.563606   \n",
       "2   feature_5   Train    1      3  0.699180  0.570147   0.572026  0.609985   \n",
       "3   feature_5   Train    1      4  0.714798  0.576672   0.578434  0.624680   \n",
       "4   feature_5    Test    1      1  0.724999  0.566540   0.541953  0.569294   \n",
       "..        ...     ...  ...    ...       ...       ...        ...       ...   \n",
       "95  feature_5   Train    4     17  0.109815  0.962480   0.954530  0.968461   \n",
       "96  feature_5   Train    4     18  0.041969  0.984502   0.987466  0.985556   \n",
       "97  feature_5   Train    4     19  0.048390  0.984502   0.987265  0.985863   \n",
       "98  feature_5   Train    4     20  0.056569  0.980424   0.980092  0.983322   \n",
       "99  feature_5    Test    4      5  0.934041  0.802281   0.732325  0.910106   \n",
       "\n",
       "          f1       auc  epoch_duration  run_duration     lr batch_size  \\\n",
       "0   0.502497  0.488002        8.442451      8.468382  0.010         50   \n",
       "1   0.542589  0.536895        0.711098      9.604316  0.010         50   \n",
       "2   0.582605  0.573741        1.050193     10.842008  0.010         50   \n",
       "3   0.594105  0.578917        0.850754     11.884248  0.010         50   \n",
       "4   0.551174  0.570118        0.714062     12.792791  0.010      50-50   \n",
       "..       ...       ...             ...           ...    ...        ...   \n",
       "95  0.961206  0.962539        0.607348     16.632527  0.001        100   \n",
       "96  0.986336  0.985014        0.709105     17.558052  0.001        100   \n",
       "97  0.986397  0.985297        0.602416     18.345972  0.001        100   \n",
       "98  0.981591  0.981391        0.621339     19.152788  0.001        100   \n",
       "99  0.811024  0.804067        0.561498     19.892809  0.001     100-50   \n",
       "\n",
       "    shuffle  \n",
       "0     False  \n",
       "1     False  \n",
       "2     False  \n",
       "3     False  \n",
       "4     False  \n",
       "..      ...  \n",
       "95    False  \n",
       "96    False  \n",
       "97    False  \n",
       "98    False  \n",
       "99    False  \n",
       "\n",
       "[100 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (bn_text): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn_digital): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc_text_1): Linear(in_features=768, out_features=128, bias=True)\n",
      "  (fc_digital_1): Linear(in_features=10, out_features=64, bias=True)\n",
      "  (fc_connect_1): Linear(in_features=192, out_features=256, bias=True)\n",
      "  (fc_connect_2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc_connect_3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc_connect_4): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "run_count = 0\n",
    "run_data = []\n",
    "\n",
    "model = None\n",
    "hightest_accuracy = 0\n",
    "\n",
    "test_run = next(iter(RunBuilder.get_run(test_params)))\n",
    "\n",
    "for run in RunBuilder.get_run(train_params):\n",
    "    \n",
    "    device = torch.device(device)\n",
    "    network = Network(X_text.shape[1], X_digital.shape[1]).to(device)\n",
    "    train_loader = Data.DataLoader(\n",
    "        Data.TensorDataset(torch.tensor(X_train).to(torch.float32), torch.tensor(y_train)),\n",
    "        batch_size=run.batch_size,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=run.shuffle\n",
    "    )\n",
    "    test_loader = Data.DataLoader(\n",
    "        Data.TensorDataset(torch.tensor(X_test).to(torch.float32), torch.tensor(y_test)),\n",
    "        batch_size=test_run.batch_size,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=test_run.shuffle\n",
    "    )\n",
    "    optimizer = optim.Adam(network.parameters(), lr=run.lr)\n",
    "    \n",
    "    run_start_time = time.time()\n",
    "    run_count += 1\n",
    "    epoch_count = 0\n",
    "    test_epoch_count = 0\n",
    "    tb = SummaryWriter(comment=f'-{run}-{flag}')\n",
    "\n",
    "    for epoch in range(20):\n",
    "        \n",
    "        epoch_start_time = time.time()\n",
    "        epoch_count += 1\n",
    "        epoch_loss = 0\n",
    "        epoch_correct_num = 0\n",
    "        epoch_precision_score = 0\n",
    "        epoch_recall_score = 0\n",
    "        epoch_f1_score = 0\n",
    "        epoch_auc_score = 0\n",
    "        for batch in train_loader:\n",
    "            \n",
    "            X_batch_train = batch[0].to(device)\n",
    "            labels_train = batch[1].to(device)\n",
    "            X_text_train, X_digital_train = X_batch_train[:, :768], X_batch_train[:, 768:]\n",
    "            preds = network(X_text_train, X_digital_train)     # 前向传播 根据权重参数进行预测 \n",
    "            loss = F.cross_entropy(preds, labels_train)  # 计算损失 构建计算图\n",
    "\n",
    "            optimizer.zero_grad()                  # pytorch会积累梯度 在优化每个batch的权重的梯度之前将之前权重的梯度置为0\n",
    "            loss.backward()                        # 在最后一个张量上调用反向传播方法 在计算图中计算权重梯度\n",
    "            optimizer.step()                       # 使用预先设置的learning_rate的梯度来更新权重参数\n",
    "\n",
    "            epoch_loss += loss.item() * train_loader.batch_size\n",
    "            epoch_correct_num += preds.argmax(dim=1).eq(labels_train).sum().item()\n",
    "            epoch_precision_score += precision_score(labels_train.to('cpu'), preds.argmax(dim=1).to('cpu'))\n",
    "            epoch_recall_score += recall_score(labels_train.to('cpu'), preds.argmax(dim=1).to('cpu'))\n",
    "            epoch_f1_score += f1_score(labels_train.to('cpu'), preds.argmax(dim=1).to('cpu'))\n",
    "            epoch_auc_score += roc_auc_score(labels_train.to('cpu'), preds.argmax(dim=1).to('cpu'))\n",
    "\n",
    "        epoch_duration = time.time() - epoch_start_time\n",
    "        run_duration = time.time() - run_start_time\n",
    "        \n",
    "        loss = epoch_loss / len(train_loader.dataset)\n",
    "        accuracy = epoch_correct_num / len(train_loader.dataset)\n",
    "        precision = epoch_precision_score / math.ceil(len(train_loader.dataset) / run.batch_size)\n",
    "        recall = epoch_recall_score / math.ceil(len(train_loader.dataset) / run.batch_size)\n",
    "        f1 = epoch_f1_score / math.ceil(len(train_loader.dataset) / run.batch_size)\n",
    "        auc = epoch_auc_score / math.ceil(len(train_loader.dataset) / run.batch_size)\n",
    "    \n",
    "        tb.add_scalar('Train Loss', loss, epoch_count)\n",
    "        tb.add_scalar('Train Accuracy', accuracy, epoch_count)\n",
    "        tb.add_scalar('Train Precision', precision, epoch_count)\n",
    "        tb.add_scalar('Train Recall', recall, epoch_count)\n",
    "        tb.add_scalar('Train F1', f1, epoch_count)\n",
    "        tb.add_scalar('Train AUC', auc, epoch_count)\n",
    "        \n",
    "        for name, param in network.named_parameters():  # 将network中的每一层参数都存入tensorboard \n",
    "            tb.add_histogram(name, param, epoch_count)\n",
    "            tb.add_histogram(f'{name}.grad', param.grad, epoch_count)\n",
    "        \n",
    "        # 保存训练参数\n",
    "        results = OrderedDict()\n",
    "        results['flag'] = flag\n",
    "        results['current'] = 'Train' \n",
    "        results['run'] = run_count\n",
    "        results['epoch'] = epoch_count\n",
    "        results['loss'] = loss\n",
    "        results['accuracy'] = accuracy\n",
    "        results['precision'] = precision\n",
    "        results['recall'] = recall\n",
    "        results['f1'] = f1\n",
    "        results['auc'] = auc\n",
    "        results['epoch_duration'] = epoch_duration\n",
    "        results['run_duration'] = run_duration\n",
    "        for k, v in run._asdict().items():\n",
    "            results[k] = v\n",
    "        run_data.append(results)\n",
    "        \n",
    "        clear_output()                   # 清除输出\n",
    "        display(pd.DataFrame(run_data))  # 输出\n",
    "        \n",
    "        #  对测试集进行预测\n",
    "        if epoch_count % 4 == 0:\n",
    "            test_epoch_start_time = time.time()\n",
    "            test_epoch_count += 1\n",
    "            test_epoch_loss = 0\n",
    "            test_epoch_correct_num = 0\n",
    "            test_epoch_precision_score = 0\n",
    "            test_epoch_recall_score = 0\n",
    "            test_epoch_f1_score = 0\n",
    "            test_epoch_auc_score = 0\n",
    "            for batch in test_loader:\n",
    "                \n",
    "                X_batch_test = batch[0].to(device)\n",
    "                labels_test = batch[1].to(device)\n",
    "                X_text_test, X_digital_test = X_batch_test[:, :768], X_batch_test[:, 768:]\n",
    "                preds = network(X_text_test, X_digital_test)          # 前向传播 根据权重参数进行预测 \n",
    "                test_loss = F.cross_entropy(preds, labels_test)  # 计算损失 构建计算图\n",
    "\n",
    "                test_epoch_loss += test_loss.item() * test_loader.batch_size\n",
    "                test_epoch_correct_num += preds.argmax(dim=1).eq(labels_test).sum().item()\n",
    "                test_epoch_precision_score += precision_score(labels_test.to('cpu'), preds.argmax(dim=1).to('cpu'))\n",
    "                test_epoch_recall_score += recall_score(labels_test.to('cpu'), preds.argmax(dim=1).to('cpu'))\n",
    "                test_epoch_f1_score += f1_score(labels_test.to('cpu'), preds.argmax(dim=1).to('cpu'))\n",
    "                test_epoch_auc_score += roc_auc_score(labels_test.to('cpu'), preds.argmax(dim=1).to('cpu'))\n",
    "\n",
    "            test_epoch_duration = time.time() - test_epoch_start_time\n",
    "            test_run_duration = time.time() - run_start_time\n",
    "\n",
    "            test_loss = test_epoch_loss / len(test_loader.dataset)\n",
    "            test_accuracy = test_epoch_correct_num / len(test_loader.dataset)\n",
    "            test_precision = test_epoch_precision_score / math.ceil(len(test_loader.dataset) / test_run.batch_size)\n",
    "            test_recall = test_epoch_recall_score / math.ceil(len(test_loader.dataset) / test_run.batch_size)\n",
    "            test_f1 = test_epoch_f1_score / math.ceil(len(test_loader.dataset) / test_run.batch_size)\n",
    "            test_auc = test_epoch_auc_score / math.ceil(len(test_loader.dataset) / test_run.batch_size)\n",
    "\n",
    "            tb.add_scalar('Test Loss', test_loss, test_epoch_count)\n",
    "            tb.add_scalar('Test Accuracy', test_accuracy, test_epoch_count)\n",
    "            tb.add_scalar('Test Precision', test_precision, test_epoch_count)\n",
    "            tb.add_scalar('Test Recall', test_recall, test_epoch_count)\n",
    "            tb.add_scalar('Test F1', test_f1, test_epoch_count)\n",
    "            tb.add_scalar('Test AUC', test_auc, test_epoch_count)\n",
    "\n",
    "            results = OrderedDict()\n",
    "            results['flag'] = flag\n",
    "            results['current'] = 'Test' \n",
    "            results['run'] = run_count\n",
    "            results['epoch'] = test_epoch_count\n",
    "            results['loss'] = test_loss\n",
    "            results['accuracy'] = test_accuracy\n",
    "            results['precision'] = test_precision\n",
    "            results['recall'] = test_recall\n",
    "            results['f1'] = test_f1\n",
    "            results['auc'] = test_auc\n",
    "            results['epoch_duration'] = test_epoch_duration\n",
    "            results['run_duration'] = test_run_duration\n",
    "            for k, v in test_run._asdict().items():\n",
    "                if k == 'lr': v = run.lr\n",
    "                if k == 'batch_size': v = str(run.batch_size) + '-' + str(v)\n",
    "                results[k] = v\n",
    "            run_data.append(results)\n",
    "\n",
    "            clear_output()\n",
    "            display(pd.DataFrame(run_data))\n",
    "        \n",
    "    if test_accuracy > hightest_accuracy:\n",
    "        hightest_accuracy = test_accuracy\n",
    "        model = network\n",
    "    tb.close()\n",
    "save_result(model, run_data)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flag</th>\n",
       "      <th>current</th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "      <th>epoch_duration</th>\n",
       "      <th>run_duration</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>shuffle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>feature_5</td>\n",
       "      <td>Test</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.934041</td>\n",
       "      <td>0.802281</td>\n",
       "      <td>0.732325</td>\n",
       "      <td>0.910106</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>0.804067</td>\n",
       "      <td>0.561498</td>\n",
       "      <td>19.892809</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100-50</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>feature_5</td>\n",
       "      <td>Test</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.550302</td>\n",
       "      <td>0.790875</td>\n",
       "      <td>0.757163</td>\n",
       "      <td>0.824792</td>\n",
       "      <td>0.787465</td>\n",
       "      <td>0.793196</td>\n",
       "      <td>0.598400</td>\n",
       "      <td>16.626544</td>\n",
       "      <td>0.010</td>\n",
       "      <td>100-50</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>feature_5</td>\n",
       "      <td>Test</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.920927</td>\n",
       "      <td>0.790875</td>\n",
       "      <td>0.720169</td>\n",
       "      <td>0.927141</td>\n",
       "      <td>0.808313</td>\n",
       "      <td>0.799335</td>\n",
       "      <td>0.630315</td>\n",
       "      <td>17.105262</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50-50</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>feature_5</td>\n",
       "      <td>Test</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.934041</td>\n",
       "      <td>0.802281</td>\n",
       "      <td>0.732325</td>\n",
       "      <td>0.910106</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>0.804067</td>\n",
       "      <td>0.561498</td>\n",
       "      <td>19.892809</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100-50</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>feature_5</td>\n",
       "      <td>Test</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.841099</td>\n",
       "      <td>0.802281</td>\n",
       "      <td>0.736393</td>\n",
       "      <td>0.905665</td>\n",
       "      <td>0.810220</td>\n",
       "      <td>0.804953</td>\n",
       "      <td>0.563524</td>\n",
       "      <td>21.270156</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50-50</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         flag current  run  epoch      loss  accuracy  precision    recall  \\\n",
       "99  feature_5    Test    4      5  0.934041  0.802281   0.732325  0.910106   \n",
       "44  feature_5    Test    2      4  0.550302  0.790875   0.757163  0.824792   \n",
       "69  feature_5    Test    3      4  0.920927  0.790875   0.720169  0.927141   \n",
       "99  feature_5    Test    4      5  0.934041  0.802281   0.732325  0.910106   \n",
       "74  feature_5    Test    3      5  0.841099  0.802281   0.736393  0.905665   \n",
       "\n",
       "          f1       auc  epoch_duration  run_duration     lr batch_size  \\\n",
       "99  0.811024  0.804067        0.561498     19.892809  0.001     100-50   \n",
       "44  0.787465  0.793196        0.598400     16.626544  0.010     100-50   \n",
       "69  0.808313  0.799335        0.630315     17.105262  0.001      50-50   \n",
       "99  0.811024  0.804067        0.561498     19.892809  0.001     100-50   \n",
       "74  0.810220  0.804953        0.563524     21.270156  0.001      50-50   \n",
       "\n",
       "    shuffle  \n",
       "99    False  \n",
       "44    False  \n",
       "69    False  \n",
       "99    False  \n",
       "74    False  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_data_df = pd.DataFrame(run_data)\n",
    "run_data_df_evaluate = run_data_df.iloc[\n",
    "    [\n",
    "        run_data_df[run_data_df['current'] == 'Test']['accuracy'].sort_values(ascending=False).index[0],\n",
    "        run_data_df[run_data_df['current'] == 'Test']['precision'].sort_values(ascending=False).index[0],\n",
    "        run_data_df[run_data_df['current'] == 'Test']['recall'].sort_values(ascending=False).index[0],\n",
    "        run_data_df[run_data_df['current'] == 'Test']['f1'].sort_values(ascending=False).index[0],\n",
    "        run_data_df[run_data_df['current'] == 'Test']['auc'].sort_values(ascending=False).index[0]\n",
    "    ],\n",
    "    :\n",
    "]\n",
    "run_data_df_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv('./results.csv')\n",
    "results = pd.concat([results, run_data_df_evaluate])\n",
    "results.to_csv('./results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
