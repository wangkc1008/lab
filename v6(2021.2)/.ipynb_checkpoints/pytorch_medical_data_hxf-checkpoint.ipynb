{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[easydl] tensorflow not available!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import math\n",
    "\n",
    "from itertools import product\n",
    "from collections import OrderedDict, namedtuple\n",
    "from easydl import clear_output\n",
    "from IPython.display import display\n",
    "import torch.utils.data as Data\n",
    "#\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score,roc_auc_score\n",
    "#\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMO = SMOTE(random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data (1132, 816)\n",
      "Counter({0: 876, 1: 256})\n",
      "(1132, 815) (1132,)\n",
      "文本数据 (1132, 768)\n",
      "数值数据 (1132, 47)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('E:/hxf_prediction/data_mimic/hxf/mimic0710/hxf/SelfData/data/total_data_xinjiao_20210125.csv')\n",
    "print('data', data.shape)\n",
    "X, y = np.array(data.drop(labels=['label'], axis=1)), np.array(data['label'].apply(int))\n",
    "print(Counter(y))\n",
    "print(X.shape, y.shape)\n",
    "X_unstructure, X_structure = X[:, 0:768], X[:, 768:]\n",
    "print('文本数据', X_unstructure.shape)\n",
    "print('数值数据', X_structure.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 876, 1: 876})\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "SMO = SMOTE(random_state=666)\n",
    "X_res,y_res = SMO.fit_resample(X,y)\n",
    "print(Counter(y_res))\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data = pd.read_csv('E:/hxf_prediction/data_mimic/hxf/mimic0710/hxf/SelfData/data/total_data_xinjiao_20210125.csv')\n",
    "print('data', data.shape)\n",
    "\n",
    "X, y = np.array(data.drop(labels=['label'], axis=1)), np.array(data['label'].apply(int))\n",
    "print(Counter(y))\n",
    "print(X.shape, y.shape)\n",
    "X_unstructure, X_structure = X[:, 0:768], X[:, 768:]\n",
    "print('文本数据', X_unstructure.shape)\n",
    "print('数值数据', X_structure.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, text_in_features, digital_in_features):\n",
    "        super(Network, self).__init__()\n",
    "        self.bn_text = nn.BatchNorm1d(text_in_features)\n",
    "        self.bn_digital = nn.BatchNorm1d(digital_in_features)\n",
    "        self.fc_text_1 = nn.Linear(in_features=text_in_features, out_features=128)\n",
    "        self.fc_digital_1 = nn.Linear(in_features=digital_in_features, out_features=64)\n",
    "        self.fc_connect_1 = nn.Linear(in_features=192, out_features=256)\n",
    "        self.fc_connect_2 = nn.Linear(in_features=256, out_features=128)\n",
    "        self.fc_connect_3 = nn.Linear(in_features=128, out_features=64)\n",
    "        self.fc_connect_4 = nn.Linear(in_features=64, out_features=2)\n",
    "\n",
    "    def forward(self, text_input, digital_input):\n",
    "        text_input_bn = self.bn_text(text_input)\n",
    "        text_1 = self.fc_text_1(text_input_bn)\n",
    "        text_1 = F.softsign(text_1)\n",
    "        \n",
    "        digital_input_bn = self.bn_digital(digital_input)\n",
    "        digital_1 = self.fc_digital_1(digital_input_bn)\n",
    "        digital_1 = F.tanh(digital_1)\n",
    "\n",
    "        t_d_connect = torch.cat([text_1, digital_1], 1)\n",
    "        t_d_connect = F.tanh(self.fc_connect_1(t_d_connect))\n",
    "        t_d_connect = F.tanh(self.fc_connect_2(t_d_connect))\n",
    "        t_d_connect = F.tanh(self.fc_connect_3(t_d_connect))\n",
    "        t_d_connect = nn.Dropout(p=0.5)(t_d_connect)\n",
    "        t_d_connect = self.fc_connect_4(t_d_connect)\n",
    "        return t_d_connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "def save_result(model, run_data):\n",
    "    \"\"\"\n",
    "    运行结果保存\n",
    "        默认文件路径 ./run_data\n",
    "        默认模型路径 ./model\n",
    "    :param model: 模型\n",
    "    :param run_data: 运行数据\n",
    "    \"\"\"\n",
    "    result_dir = './run_data'\n",
    "    model_dir = './model'\n",
    "    name = 'result'\n",
    "    \n",
    "    if not os.path.exists(result_dir):\n",
    "        os.mkdir(result_dir)\n",
    "        \n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "    \n",
    "    time_index = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    # 保存运行文件\n",
    "    run_data_path = os.path.join(result_dir, name)\n",
    "    pd.DataFrame(run_data).to_csv(f'{run_data_path}_{time_index}.csv', index=False)\n",
    "    with open(f'{run_data_path}_{time_index}.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(run_data, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    # 保存运行模型\n",
    "    model_path = os.path.join(model_dir, name)\n",
    "    torch.save(model.state_dict(), f'{model_path}_{time_index}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunBuilder:\n",
    "    @staticmethod\n",
    "    def get_run(params):  # 静态方法，不需要实例化\n",
    "\n",
    "        Run = namedtuple('Run', params.keys())\n",
    "        runs = []\n",
    "        for v in product(*params.values()):\n",
    "            runs.append(Run(*v))\n",
    "\n",
    "        return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1226, 815) (526, 815) (1226,) (526,)\n"
     ]
    }
   ],
   "source": [
    "train_params = OrderedDict(\n",
    "    lr = [.01, .001],\n",
    "    batch_size = [50, 100],\n",
    "    shuffle = [False],\n",
    "    device = ['cuda'],\n",
    "    num_workers = [1]  # 有多少子进程被用来加载数据 默认为0即在主进程中加载数据 可以利用多核CPU的特点指定num_workers个数 提前将数据加载到内存中\n",
    ")\n",
    "\n",
    "test_params = OrderedDict(\n",
    "    lr = [np.nan],\n",
    "    batch_size = [50],\n",
    "    shuffle = [False],\n",
    "    device = ['cuda'],\n",
    "    num_workers = [1]  # 有多少子进程被用来加载数据 默认为0即在主进程中加载数据 可以利用多核CPU的特点指定num_workers个数 提前将数据加载到内存中\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.3, random_state=np.random.seed())\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current</th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>epoch duration</th>\n",
       "      <th>run duration</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>shuffle</th>\n",
       "      <th>device</th>\n",
       "      <th>num_workers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.767473</td>\n",
       "      <td>0.465796</td>\n",
       "      <td>0.490947</td>\n",
       "      <td>0.519576</td>\n",
       "      <td>7.659516</td>\n",
       "      <td>7.671487</td>\n",
       "      <td>0.010</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>cuda</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.718011</td>\n",
       "      <td>0.507659</td>\n",
       "      <td>0.511024</td>\n",
       "      <td>0.517945</td>\n",
       "      <td>0.669183</td>\n",
       "      <td>8.683779</td>\n",
       "      <td>0.010</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>cuda</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.694284</td>\n",
       "      <td>0.576045</td>\n",
       "      <td>0.593379</td>\n",
       "      <td>0.592170</td>\n",
       "      <td>0.673200</td>\n",
       "      <td>9.545476</td>\n",
       "      <td>0.010</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>cuda</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.674099</td>\n",
       "      <td>0.613962</td>\n",
       "      <td>0.642423</td>\n",
       "      <td>0.635400</td>\n",
       "      <td>0.656271</td>\n",
       "      <td>10.396228</td>\n",
       "      <td>0.010</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>cuda</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.605749</td>\n",
       "      <td>0.688430</td>\n",
       "      <td>0.691426</td>\n",
       "      <td>0.696574</td>\n",
       "      <td>0.666219</td>\n",
       "      <td>11.260889</td>\n",
       "      <td>0.010</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>cuda</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>Train</td>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.578427</td>\n",
       "      <td>50.636606</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>cuda</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Train</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.571501</td>\n",
       "      <td>51.378650</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>cuda</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>Train</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.578454</td>\n",
       "      <td>52.136595</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>cuda</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Train</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.634327</td>\n",
       "      <td>52.951441</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>cuda</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>Test</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1.235761</td>\n",
       "      <td>0.713712</td>\n",
       "      <td>0.679363</td>\n",
       "      <td>0.823194</td>\n",
       "      <td>0.570504</td>\n",
       "      <td>53.702438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>cuda</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    current  run  epoch      loss        f1  precision  accuracy  \\\n",
       "0     Train    1      1  0.767473  0.465796   0.490947  0.519576   \n",
       "1     Train    1      2  0.718011  0.507659   0.511024  0.517945   \n",
       "2     Train    1      3  0.694284  0.576045   0.593379  0.592170   \n",
       "3     Train    1      4  0.674099  0.613962   0.642423  0.635400   \n",
       "4     Train    1      5  0.605749  0.688430   0.691426  0.696574   \n",
       "..      ...  ...    ...       ...       ...        ...       ...   \n",
       "283   Train    4     57  0.000184  1.000000   1.000000  1.000000   \n",
       "284   Train    4     58  0.000168  1.000000   1.000000  1.000000   \n",
       "285   Train    4     59  0.000168  1.000000   1.000000  1.000000   \n",
       "286   Train    4     60  0.000171  1.000000   1.000000  1.000000   \n",
       "287    Test    4     12  1.235761  0.713712   0.679363  0.823194   \n",
       "\n",
       "     epoch duration  run duration     lr  batch_size  shuffle device  \\\n",
       "0          7.659516      7.671487  0.010          50    False   cuda   \n",
       "1          0.669183      8.683779  0.010          50    False   cuda   \n",
       "2          0.673200      9.545476  0.010          50    False   cuda   \n",
       "3          0.656271     10.396228  0.010          50    False   cuda   \n",
       "4          0.666219     11.260889  0.010          50    False   cuda   \n",
       "..              ...           ...    ...         ...      ...    ...   \n",
       "283        0.578427     50.636606  0.001         100    False   cuda   \n",
       "284        0.571501     51.378650  0.001         100    False   cuda   \n",
       "285        0.578454     52.136595  0.001         100    False   cuda   \n",
       "286        0.634327     52.951441  0.001         100    False   cuda   \n",
       "287        0.570504     53.702438    NaN          50    False   cuda   \n",
       "\n",
       "     num_workers  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  \n",
       "..           ...  \n",
       "283            1  \n",
       "284            1  \n",
       "285            1  \n",
       "286            1  \n",
       "287            1  \n",
       "\n",
       "[288 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集准确率: 0.8231939163498099\n",
      "Network(\n",
      "  (bn_text): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn_digital): BatchNorm1d(47, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc_text_1): Linear(in_features=768, out_features=128, bias=True)\n",
      "  (fc_digital_1): Linear(in_features=47, out_features=64, bias=True)\n",
      "  (fc_connect_1): Linear(in_features=192, out_features=256, bias=True)\n",
      "  (fc_connect_2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc_connect_3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc_connect_4): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "run_count = 0\n",
    "run_data = []\n",
    "\n",
    "model = None\n",
    "hightest_accuracy = 0\n",
    "\n",
    "test_run = next(iter(RunBuilder.get_run(test_params)))\n",
    "\n",
    "for run in RunBuilder.get_run(train_params):\n",
    "    \n",
    "    device = torch.device(run.device)\n",
    "    network = Network(X_unstructure.shape[1], X_structure.shape[1]).to(device)\n",
    "    train_loader = Data.DataLoader(\n",
    "        Data.TensorDataset(torch.tensor(X_train).to(torch.float32), torch.tensor(y_train)),\n",
    "        batch_size=run.batch_size,\n",
    "        num_workers=run.num_workers,\n",
    "        shuffle=run.shuffle\n",
    "    )\n",
    "    test_loader = Data.DataLoader(\n",
    "        Data.TensorDataset(torch.tensor(X_test).to(torch.float32), torch.tensor(y_test)),\n",
    "        batch_size=test_run.batch_size,\n",
    "        num_workers=test_run.num_workers,\n",
    "        shuffle=test_run.shuffle\n",
    "    )\n",
    "    optimizer = optim.Adam(network.parameters(), lr=run.lr)\n",
    "    \n",
    "    run_start_time = time.time()\n",
    "    run_count += 1\n",
    "    epoch_count = 0\n",
    "    test_epoch_count = 0\n",
    "    tb = SummaryWriter(comment=f'-{run}')\n",
    "\n",
    "    for epoch in range(60):\n",
    "        \n",
    "        epoch_start_time = time.time()\n",
    "        epoch_count += 1\n",
    "        epoch_loss = 0\n",
    "        epoch_correct_num = 0\n",
    "        epoch_precision = 0\n",
    "        epoch_f1 = 0\n",
    "        for batch in train_loader:\n",
    "            \n",
    "            X_batch_train = batch[0].to(device)\n",
    "            labels_train = batch[1].to(device)\n",
    "            X_text_train, X_digital_train = X_batch_train[:, :768], X_batch_train[:, 768:]\n",
    "            preds = network(X_text_train, X_digital_train)     # 前向传播 根据权重参数进行预测 \n",
    "            loss = F.cross_entropy(preds, labels_train)  # 计算损失 构建计算图\n",
    "\n",
    "            optimizer.zero_grad()                  # pytorch会积累梯度 在优化每个batch的权重的梯度之前将之前权重的梯度置为0\n",
    "            loss.backward()                        # 在最后一个张量上调用反向传播方法 在计算图中计算权重梯度\n",
    "            optimizer.step()                       # 使用预先设置的learning_rate的梯度来更新权重参数\n",
    "\n",
    "            epoch_loss += loss.item() * train_loader.batch_size\n",
    "            epoch_correct_num += preds.argmax(dim=1).eq(labels_train).sum().item()\n",
    "            epoch_f1 += f1_score(labels_train.to('cpu'), preds.argmax(dim=1).to('cpu'))\n",
    "            epoch_recall = recall_score(labels_train, preds.argmax(dim=1))\n",
    "            epoch_precision += precision_score(labels_train.to('cpu'), preds.argmax(dim=1).to('cpu'))\n",
    "            epoch_rocauc = roc_auc_score(labels_train, preds.argmax(dim=1))\n",
    "            \n",
    "        epoch_duration = time.time() - epoch_start_time\n",
    "        run_duration = time.time() - run_start_time\n",
    "        \n",
    "        loss = epoch_loss / len(train_loader.dataset)\n",
    "        accuracy = epoch_correct_num / len(train_loader.dataset)\n",
    "        f1 =  epoch_f1 / math.ceil(len(train_loader.dataset)/run.batch_size)\n",
    "        #recall = epoch_f1 / len(train_loader.dataset)\n",
    "        precision = epoch_precision / math.ceil(len(train_loader.dataset)/run.batch_size)\n",
    "        #rocauc = epoch_rocauc / len(train_loader.dataset)\n",
    "        \n",
    "        tb.add_scalar('Train Loss', loss, epoch_count)\n",
    "        tb.add_scalar('Train Accuracy', accuracy, epoch_count)\n",
    "        \n",
    "        for name, param in network.named_parameters():  # 将network中的每一层参数都存入tensorboard \n",
    "            tb.add_histogram(name, param, epoch_count)\n",
    "            tb.add_histogram(f'{name}.grad', param.grad, epoch_count)\n",
    "        \n",
    "        # 保存训练参数\n",
    "        results = OrderedDict()\n",
    "        results['current'] = 'Train' \n",
    "        results['run'] = run_count\n",
    "        results['epoch'] = epoch_count\n",
    "        results['loss'] = loss\n",
    "        results['f1'] = f1\n",
    "        #results['recall'] = recall\n",
    "        results['precision'] = precision\n",
    "        #results['rocauc'] = recall\n",
    "        results['accuracy'] = accuracy\n",
    "        results['epoch duration'] = epoch_duration\n",
    "        results['run duration'] = run_duration\n",
    "        for k, v in run._asdict().items():\n",
    "            results[k] = v\n",
    "        run_data.append(results)\n",
    "        \n",
    "        clear_output()                   # 清除输出\n",
    "        display(pd.DataFrame(run_data))  # 输出\n",
    "        \n",
    "        #  对测试集进行预测\n",
    "        if epoch_count % 5 == 0:\n",
    "            test_epoch_start_time = time.time()\n",
    "            test_epoch_count += 1\n",
    "            test_epoch_loss = 0\n",
    "            test_epoch_correct_num = 0\n",
    "            test_epoch_precision = 0\n",
    "            test_epoch_f1 = 0\n",
    "            for batch in test_loader:\n",
    "                \n",
    "                X_batch_test = batch[0].to(device)\n",
    "                labels_test = batch[1].to(device)\n",
    "                X_text_test, X_digital_test = X_batch_test[:, :768], X_batch_test[:, 768:]\n",
    "                preds = network(X_text_test, X_digital_test)          # 前向传播 根据权重参数进行预测 \n",
    "                test_loss = F.cross_entropy(preds, labels_test)  # 计算损失 构建计算图\n",
    "\n",
    "                test_epoch_loss += test_loss.item() * test_loader.batch_size\n",
    "                test_epoch_correct_num += preds.argmax(dim=1).eq(labels_test).sum().item()\n",
    "                test_epoch_precision += precision_score(labels_test.to('cpu'), preds.argmax(dim=1).to('cpu'))\n",
    "                test_epoch_f1 += f1_score(labels_test.to('cpu'), preds.argmax(dim=1).to('cpu'))\n",
    "            test_epoch_duration = time.time() - test_epoch_start_time\n",
    "            test_run_duration = time.time() - run_start_time\n",
    "\n",
    "            test_loss = test_epoch_loss / len(test_loader.dataset)\n",
    "            test_accuracy = test_epoch_correct_num / len(test_loader.dataset)\n",
    "            precision = test_epoch_precision / math.ceil(len(train_loader.dataset)/run.batch_size)\n",
    "            f1 =  test_epoch_f1 / math.ceil(len(train_loader.dataset)/run.batch_size)\n",
    "\n",
    "            tb.add_scalar('Test Loss', test_loss, test_epoch_count)\n",
    "            tb.add_scalar('Test Accuracy', test_accuracy, test_epoch_count)\n",
    "\n",
    "            results = OrderedDict()\n",
    "            results['current'] = 'Test' \n",
    "            results['run'] = run_count\n",
    "            results['epoch'] = test_epoch_count\n",
    "            results['precision'] = precision\n",
    "            results['f1'] = f1\n",
    "            results['loss'] = test_loss\n",
    "            results['accuracy'] = test_accuracy\n",
    "            results['epoch duration'] = test_epoch_duration\n",
    "            results['run duration'] = test_run_duration\n",
    "            for k, v in test_run._asdict().items():\n",
    "                results[k] = v\n",
    "            run_data.append(results)\n",
    "\n",
    "            clear_output()\n",
    "            display(pd.DataFrame(run_data))\n",
    "        \n",
    "    if test_accuracy > hightest_accuracy:\n",
    "        hightest_accuracy = test_accuracy\n",
    "        model = network\n",
    "    tb.close()\n",
    "save_result(model, run_data)\n",
    "print('测试集准确率: %s'% hightest_accuracy)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
