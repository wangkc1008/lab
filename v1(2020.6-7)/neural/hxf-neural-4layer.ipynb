{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5199, 309)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_data_100_5079_replace = pd.read_csv('E:/hxf prediction/data_mimic/hxf/notes_extract/total_code/mixed_data_0717_drop_replace_fill_100_5079.csv')\n",
    "mixed_data_100_5079_replace.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6_x</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>50963</th>\n",
       "      <th>50909</th>\n",
       "      <th>50903</th>\n",
       "      <th>50904</th>\n",
       "      <th>50905</th>\n",
       "      <th>50907</th>\n",
       "      <th>51000</th>\n",
       "      <th>50906</th>\n",
       "      <th>age</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.007089</td>\n",
       "      <td>0.004145</td>\n",
       "      <td>0.038405</td>\n",
       "      <td>-0.052687</td>\n",
       "      <td>-0.049249</td>\n",
       "      <td>0.070052</td>\n",
       "      <td>-0.030874</td>\n",
       "      <td>0.028542</td>\n",
       "      <td>0.068825</td>\n",
       "      <td>0.091948</td>\n",
       "      <td>...</td>\n",
       "      <td>10558.00</td>\n",
       "      <td>34.3</td>\n",
       "      <td>4.04</td>\n",
       "      <td>43.74</td>\n",
       "      <td>89.0</td>\n",
       "      <td>158.92</td>\n",
       "      <td>139.06</td>\n",
       "      <td>99.16</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.046269</td>\n",
       "      <td>-0.017732</td>\n",
       "      <td>0.040526</td>\n",
       "      <td>-0.074210</td>\n",
       "      <td>-0.037897</td>\n",
       "      <td>0.060724</td>\n",
       "      <td>-0.016219</td>\n",
       "      <td>0.055877</td>\n",
       "      <td>0.110071</td>\n",
       "      <td>0.088731</td>\n",
       "      <td>...</td>\n",
       "      <td>15219.75</td>\n",
       "      <td>34.3</td>\n",
       "      <td>4.04</td>\n",
       "      <td>43.74</td>\n",
       "      <td>89.0</td>\n",
       "      <td>158.92</td>\n",
       "      <td>139.06</td>\n",
       "      <td>99.16</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.048322</td>\n",
       "      <td>-0.043990</td>\n",
       "      <td>0.016089</td>\n",
       "      <td>-0.098154</td>\n",
       "      <td>-0.019360</td>\n",
       "      <td>0.066105</td>\n",
       "      <td>-0.010958</td>\n",
       "      <td>0.058539</td>\n",
       "      <td>0.120996</td>\n",
       "      <td>0.113395</td>\n",
       "      <td>...</td>\n",
       "      <td>15219.75</td>\n",
       "      <td>34.3</td>\n",
       "      <td>4.04</td>\n",
       "      <td>43.74</td>\n",
       "      <td>89.0</td>\n",
       "      <td>158.92</td>\n",
       "      <td>139.06</td>\n",
       "      <td>99.16</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.008100</td>\n",
       "      <td>-0.033179</td>\n",
       "      <td>0.025611</td>\n",
       "      <td>-0.066074</td>\n",
       "      <td>-0.032589</td>\n",
       "      <td>0.076273</td>\n",
       "      <td>-0.043867</td>\n",
       "      <td>0.045307</td>\n",
       "      <td>0.068330</td>\n",
       "      <td>0.083049</td>\n",
       "      <td>...</td>\n",
       "      <td>15219.75</td>\n",
       "      <td>34.3</td>\n",
       "      <td>4.04</td>\n",
       "      <td>43.74</td>\n",
       "      <td>89.0</td>\n",
       "      <td>174.00</td>\n",
       "      <td>139.06</td>\n",
       "      <td>99.16</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.082258</td>\n",
       "      <td>-0.013484</td>\n",
       "      <td>0.004785</td>\n",
       "      <td>-0.071620</td>\n",
       "      <td>-0.047045</td>\n",
       "      <td>0.049379</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>0.059376</td>\n",
       "      <td>0.113682</td>\n",
       "      <td>0.106364</td>\n",
       "      <td>...</td>\n",
       "      <td>15219.75</td>\n",
       "      <td>34.3</td>\n",
       "      <td>4.04</td>\n",
       "      <td>43.74</td>\n",
       "      <td>89.0</td>\n",
       "      <td>158.92</td>\n",
       "      <td>139.06</td>\n",
       "      <td>99.16</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5194</th>\n",
       "      <td>-0.021533</td>\n",
       "      <td>-0.024169</td>\n",
       "      <td>0.038631</td>\n",
       "      <td>-0.054892</td>\n",
       "      <td>-0.038952</td>\n",
       "      <td>0.077706</td>\n",
       "      <td>-0.036869</td>\n",
       "      <td>0.039681</td>\n",
       "      <td>0.081134</td>\n",
       "      <td>0.065088</td>\n",
       "      <td>...</td>\n",
       "      <td>15219.75</td>\n",
       "      <td>34.3</td>\n",
       "      <td>4.04</td>\n",
       "      <td>43.74</td>\n",
       "      <td>89.0</td>\n",
       "      <td>158.92</td>\n",
       "      <td>139.06</td>\n",
       "      <td>99.16</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5195</th>\n",
       "      <td>-0.038366</td>\n",
       "      <td>0.003058</td>\n",
       "      <td>0.030392</td>\n",
       "      <td>-0.053761</td>\n",
       "      <td>-0.034978</td>\n",
       "      <td>0.068232</td>\n",
       "      <td>-0.028096</td>\n",
       "      <td>0.049303</td>\n",
       "      <td>0.105394</td>\n",
       "      <td>0.074794</td>\n",
       "      <td>...</td>\n",
       "      <td>15219.75</td>\n",
       "      <td>34.3</td>\n",
       "      <td>2.80</td>\n",
       "      <td>66.00</td>\n",
       "      <td>102.0</td>\n",
       "      <td>188.00</td>\n",
       "      <td>101.00</td>\n",
       "      <td>99.16</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5196</th>\n",
       "      <td>-0.015536</td>\n",
       "      <td>-0.042503</td>\n",
       "      <td>0.009408</td>\n",
       "      <td>-0.054958</td>\n",
       "      <td>-0.025101</td>\n",
       "      <td>0.075214</td>\n",
       "      <td>-0.017778</td>\n",
       "      <td>0.059893</td>\n",
       "      <td>0.092698</td>\n",
       "      <td>0.055450</td>\n",
       "      <td>...</td>\n",
       "      <td>15219.75</td>\n",
       "      <td>34.3</td>\n",
       "      <td>4.04</td>\n",
       "      <td>43.74</td>\n",
       "      <td>89.0</td>\n",
       "      <td>158.92</td>\n",
       "      <td>139.06</td>\n",
       "      <td>99.16</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5197</th>\n",
       "      <td>-0.097241</td>\n",
       "      <td>0.007172</td>\n",
       "      <td>0.017310</td>\n",
       "      <td>-0.056375</td>\n",
       "      <td>-0.059922</td>\n",
       "      <td>0.028442</td>\n",
       "      <td>0.012607</td>\n",
       "      <td>0.055554</td>\n",
       "      <td>0.116205</td>\n",
       "      <td>0.118019</td>\n",
       "      <td>...</td>\n",
       "      <td>15219.75</td>\n",
       "      <td>34.3</td>\n",
       "      <td>4.04</td>\n",
       "      <td>43.74</td>\n",
       "      <td>89.0</td>\n",
       "      <td>158.92</td>\n",
       "      <td>139.06</td>\n",
       "      <td>99.16</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5198</th>\n",
       "      <td>-0.029792</td>\n",
       "      <td>-0.024298</td>\n",
       "      <td>0.029648</td>\n",
       "      <td>-0.059690</td>\n",
       "      <td>-0.031142</td>\n",
       "      <td>0.057555</td>\n",
       "      <td>-0.009290</td>\n",
       "      <td>0.045681</td>\n",
       "      <td>0.106409</td>\n",
       "      <td>0.078930</td>\n",
       "      <td>...</td>\n",
       "      <td>15219.75</td>\n",
       "      <td>34.3</td>\n",
       "      <td>4.04</td>\n",
       "      <td>43.74</td>\n",
       "      <td>89.0</td>\n",
       "      <td>158.92</td>\n",
       "      <td>139.06</td>\n",
       "      <td>99.16</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5199 rows × 308 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             1         2         3         4         5       6_x         7  \\\n",
       "0    -0.007089  0.004145  0.038405 -0.052687 -0.049249  0.070052 -0.030874   \n",
       "1    -0.046269 -0.017732  0.040526 -0.074210 -0.037897  0.060724 -0.016219   \n",
       "2    -0.048322 -0.043990  0.016089 -0.098154 -0.019360  0.066105 -0.010958   \n",
       "3    -0.008100 -0.033179  0.025611 -0.066074 -0.032589  0.076273 -0.043867   \n",
       "4    -0.082258 -0.013484  0.004785 -0.071620 -0.047045  0.049379  0.002257   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5194 -0.021533 -0.024169  0.038631 -0.054892 -0.038952  0.077706 -0.036869   \n",
       "5195 -0.038366  0.003058  0.030392 -0.053761 -0.034978  0.068232 -0.028096   \n",
       "5196 -0.015536 -0.042503  0.009408 -0.054958 -0.025101  0.075214 -0.017778   \n",
       "5197 -0.097241  0.007172  0.017310 -0.056375 -0.059922  0.028442  0.012607   \n",
       "5198 -0.029792 -0.024298  0.029648 -0.059690 -0.031142  0.057555 -0.009290   \n",
       "\n",
       "             8         9        10  ...     50963  50909  50903  50904  50905  \\\n",
       "0     0.028542  0.068825  0.091948  ...  10558.00   34.3   4.04  43.74   89.0   \n",
       "1     0.055877  0.110071  0.088731  ...  15219.75   34.3   4.04  43.74   89.0   \n",
       "2     0.058539  0.120996  0.113395  ...  15219.75   34.3   4.04  43.74   89.0   \n",
       "3     0.045307  0.068330  0.083049  ...  15219.75   34.3   4.04  43.74   89.0   \n",
       "4     0.059376  0.113682  0.106364  ...  15219.75   34.3   4.04  43.74   89.0   \n",
       "...        ...       ...       ...  ...       ...    ...    ...    ...    ...   \n",
       "5194  0.039681  0.081134  0.065088  ...  15219.75   34.3   4.04  43.74   89.0   \n",
       "5195  0.049303  0.105394  0.074794  ...  15219.75   34.3   2.80  66.00  102.0   \n",
       "5196  0.059893  0.092698  0.055450  ...  15219.75   34.3   4.04  43.74   89.0   \n",
       "5197  0.055554  0.116205  0.118019  ...  15219.75   34.3   4.04  43.74   89.0   \n",
       "5198  0.045681  0.106409  0.078930  ...  15219.75   34.3   4.04  43.74   89.0   \n",
       "\n",
       "       50907   51000  50906   age  flag  \n",
       "0     158.92  139.06  99.16  85.0   1.0  \n",
       "1     158.92  139.06  99.16  67.0   0.0  \n",
       "2     158.92  139.06  99.16  67.0   0.0  \n",
       "3     174.00  139.06  99.16  84.0   1.0  \n",
       "4     158.92  139.06  99.16  58.0   0.0  \n",
       "...      ...     ...    ...   ...   ...  \n",
       "5194  158.92  139.06  99.16  75.0   1.0  \n",
       "5195  188.00  101.00  99.16  69.0   1.0  \n",
       "5196  158.92  139.06  99.16  89.0   1.0  \n",
       "5197  158.92  139.06  99.16  86.0   0.0  \n",
       "5198  158.92  139.06  99.16  86.0   0.0  \n",
       "\n",
       "[5199 rows x 308 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_data_100_5079_replace = mixed_data_100_5079_replace.drop(labels=['Unnamed: 0'], axis=1)\n",
    "mixed_data_100_5079_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corr_data = data.corr()['expire_flag'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in_corr_data = data[corr_data[(corr_data > 0.1) | (corr_data > -0.1)].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = np.array(mixed_data_100_5079_replace.drop(labels=['flag'], axis=1)), np.array(mixed_data_100_5079_replace['flag'].apply(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5199, 307)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=666,test_size = 0.33 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.  ,   1.  ,   2.  , ..., 139.06,  99.16,  61.  ],\n",
       "       [  4.  ,   5.  ,   3.  , ..., 139.06,  99.16,  87.  ],\n",
       "       [  1.  ,   0.  ,   2.  , ..., 139.06,  99.16,  46.  ],\n",
       "       ...,\n",
       "       [  0.  ,   3.  ,   0.  , ..., 112.  ,  99.16,  88.  ],\n",
       "       [  1.  ,   1.  ,   0.  , ..., 139.06,  99.16,  56.  ],\n",
       "       [  3.  ,   1.  ,   0.  , ...,  69.  ,  99.16,  74.  ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vec, X_train_need_scale = X_train[:, 0:200], X_train[:, 200:]\n",
    "X_train_need_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0616547 , -0.00719389,  0.02209863, ...,  0.04419197,\n",
       "         0.04840468,  0.1125212 ],\n",
       "       [-0.04367821, -0.00468176,  0.01873666, ...,  0.06050809,\n",
       "         0.07758447,  0.08507637],\n",
       "       [-0.01103216, -0.023751  ,  0.02704758, ...,  0.04251143,\n",
       "         0.04903732,  0.10087774],\n",
       "       ...,\n",
       "       [-0.0687694 ,  0.00432208,  0.03931623, ...,  0.05896778,\n",
       "         0.05197511,  0.127062  ],\n",
       "       [-0.10637879, -0.0293281 ,  0.0025199 , ...,  0.04118515,\n",
       "         0.07000919,  0.10419425],\n",
       "       [-0.0150273 ,  0.01286628,  0.01903607, ...,  0.06682524,\n",
       "         0.04598877,  0.11499347]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3483, 200)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3483, 107)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_need_scale.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.  ,   3.  ,   0.  , ..., 139.06,  99.16,  62.  ],\n",
       "       [  0.  ,   2.  ,   0.  , ..., 109.  ,  99.16,  83.  ],\n",
       "       [  1.  ,   0.  ,   0.  , ..., 139.06,  99.16,  75.  ],\n",
       "       ...,\n",
       "       [  4.  ,  10.  ,   1.  , ..., 139.06,  99.16,  84.  ],\n",
       "       [  1.  ,   4.  ,   2.  , ..., 139.06,  99.16,  68.  ],\n",
       "       [  0.  ,   0.  ,   0.  , ..., 139.06,  99.16,  69.  ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_vec, X_test_need_scale = X_test[:, 0:200], X_test[:, 200:]\n",
    "X_test_need_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0150447 , -0.01556175,  0.02948797, ...,  0.0314746 ,\n",
       "         0.0437981 ,  0.08663017],\n",
       "       [-0.04189379, -0.00865391,  0.03074749, ...,  0.04190846,\n",
       "         0.05817086,  0.1084365 ],\n",
       "       [-0.06006065, -0.00641395, -0.00533319, ...,  0.02041156,\n",
       "         0.04046414,  0.1378125 ],\n",
       "       ...,\n",
       "       [-0.03235763, -0.01355557,  0.02959701, ...,  0.0397548 ,\n",
       "         0.06472966,  0.10936951],\n",
       "       [-0.04433653, -0.026616  ,  0.01592735, ...,  0.04744394,\n",
       "         0.05462258,  0.10160053],\n",
       "       [-0.0436074 , -0.00051947,  0.03306991, ...,  0.05579429,\n",
       "         0.04935778,  0.12380271]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_scaler = StandardScaler()\n",
    "standard_scaler.fit(X_train_need_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.92276773e+00, 1.77031295e+00, 9.43152455e-01, 8.25150732e-01,\n",
       "       3.29413724e+02, 3.93051967e-01, 3.06643698e+01, 2.63313236e-01,\n",
       "       6.49038185e-02, 5.63928682e+01, 1.22400287e+02, 3.14450359e+01,\n",
       "       1.95047947e+01, 6.11076947e+01, 1.14967557e+01, 1.54853959e+02,\n",
       "       4.31105627e+01, 1.38360034e+02, 1.17209483e+02, 8.39076946e+00,\n",
       "       5.73153747e+01, 6.02228309e+01, 1.92120385e+01, 1.06151220e+01,\n",
       "       1.01652024e+00, 3.11024235e+01, 1.36713178e+00, 1.04946196e+02,\n",
       "       1.57793982e+02, 3.72003279e+03, 1.38028814e+02, 1.15352719e+02,\n",
       "       7.98115705e+01, 5.10340798e+00, 1.15746942e+02, 4.16648866e+00,\n",
       "       1.49531036e+01, 1.38579437e+02, 1.45464278e+02, 1.22751163e+01,\n",
       "       1.29007034e+01, 2.73993115e+00, 2.94938530e+01, 5.61876543e+01,\n",
       "       5.80802756e+01, 1.09907936e+02, 1.75101924e-01, 5.56662590e+01,\n",
       "       1.36375263e+02, 1.35886882e+02, 1.44291631e+02, 2.90510393e+01,\n",
       "       2.01042205e+00, 2.18291398e+02, 8.34460237e+00, 2.40643239e+01,\n",
       "       1.60728699e+02, 2.69450434e+03, 3.59665547e+02, 3.19377954e+01,\n",
       "       1.08646914e+01, 1.47621390e+01, 3.71498421e+00, 4.15067471e+00,\n",
       "       3.59409130e+00, 1.38365418e+02, 1.45300534e+02, 1.01811944e+01,\n",
       "       7.31094746e+00, 1.22967844e+01, 5.07258111e-01, 1.22855843e+01,\n",
       "       3.38227735e+01, 1.47809044e+01, 1.48659144e+01, 3.61699110e+00,\n",
       "       1.08979529e+01, 1.32399265e+02, 7.39322194e+01, 3.20157910e+00,\n",
       "       9.71043296e+01, 1.41410910e+01, 1.26933026e+02, 2.52899167e+01,\n",
       "       8.53154177e+00, 1.53306919e+00, 4.51264387e+02, 2.96495837e+01,\n",
       "       3.22682458e+01, 1.09052570e+01, 1.38102785e+00, 3.60875969e+00,\n",
       "       1.08484065e-01, 5.73051392e+00, 6.48305182e+02, 1.44193081e+01,\n",
       "       7.77353287e+01, 4.10204709e+01, 1.52384170e+04, 3.43843813e+01,\n",
       "       4.07695665e+00, 4.36159231e+01, 8.91366638e+01, 1.59171932e+02,\n",
       "       1.40700924e+02, 9.91615389e+01, 7.04806202e+01])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_scaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_standard = standard_scaler.transform(X_train_need_scale)\n",
    "X_test_standard = standard_scaler.transform(X_test_need_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3483, 107)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_standard.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1716, 107)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_standard.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_standard = np.hstack((X_train_vec, X_train_standard))\n",
    "X_test_standard = np.hstack((X_test_vec, X_test_standard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3483, 307)\n",
      "(1716, 307)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_standard.shape)\n",
    "print(X_test_standard.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3483, 307)\n",
      "(3483,)\n",
      "(1716, 307)\n",
      "(1716,)\n"
     ]
    }
   ],
   "source": [
    "# def load_data(filename):\n",
    "#     \"\"\"read data from data file.\"\"\"\n",
    "#     with open(filename, 'rb') as f:\n",
    "#         data = pickle.load(f, encoding='bytes')\n",
    "#         return data[b'data'], data[b'labels']\n",
    "\n",
    "# tensorflow.Dataset.\n",
    "class DiseaseData:\n",
    "    def __init__(self, train_model=True, need_shuffle=True):\n",
    "        if train_model:\n",
    "            self._data = X_train_standard\n",
    "            self._labels = y_train\n",
    "        else:\n",
    "            self._data = X_test_standard\n",
    "            self._labels = y_test\n",
    "        print(self._data.shape)\n",
    "#         print(self._data.dtype)\n",
    "        print(self._labels.shape)\n",
    "#         print(self._labels.dtype)\n",
    "\n",
    "        self._num_examples = self._data.shape[0]\n",
    "        self._need_shuffle = need_shuffle\n",
    "        self._indicator = 0\n",
    "        if self._need_shuffle:\n",
    "            self._shuffle_data()\n",
    "            \n",
    "    def _shuffle_data(self):\n",
    "        # [0,1,2,3,4,5] -> [5,3,2,4,0,1]\n",
    "        p = np.random.permutation(self._num_examples)\n",
    "        self._data = self._data[p]\n",
    "        self._labels = self._labels[p]\n",
    "    \n",
    "    def next_batch(self, batch_size):\n",
    "        \"\"\"return batch_size examples as a batch.\"\"\"\n",
    "        end_indicator = self._indicator + batch_size\n",
    "        if end_indicator > self._num_examples:\n",
    "            if self._need_shuffle:\n",
    "                self._shuffle_data()\n",
    "                self._indicator = 0\n",
    "                end_indicator = batch_size\n",
    "            else:\n",
    "                raise Exception(\"have no more examples\")\n",
    "        if end_indicator > self._num_examples:\n",
    "            raise Exception(\"batch size is larger than all examples\")\n",
    "        batch_data = self._data[self._indicator: end_indicator]\n",
    "        batch_labels = self._labels[self._indicator: end_indicator]\n",
    "        self._indicator = end_indicator\n",
    "        return batch_data, batch_labels\n",
    "\n",
    "train_data = DiseaseData(True, True)\n",
    "test_data = DiseaseData(False, False)\n",
    "# test_data.next_batch(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = tf.placeholder(tf.float32, [None, 94])\n",
    "# # [None], eg: [0,5,6,3]\n",
    "# y = tf.placeholder(tf.int64, [None])\n",
    "# hidden1 = tf.layers.dense(x, 100, activation=tf.nn.relu)\n",
    "# hidden2 = tf.layers.dense(hidden1, 100, activation=tf.nn.relu)\n",
    "# hidden3 = tf.layers.dense(hidden2, 50, activation=tf.nn.relu)\n",
    "# y_ = tf.layers.dense(hidden3, 1)\n",
    "\n",
    "\n",
    "# # loss = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=y_)\n",
    "# # y_ -> sofmax\n",
    "# # y -> one_hot\n",
    "# # loss = ylogy_\n",
    "\n",
    "# # indices\n",
    "# # [None, 1]\n",
    "# p_y_1 = tf.nn.sigmoid(y_)\n",
    "# # [None, 1]\n",
    "# y_reshaped = tf.reshape(y, (-1, 1))\n",
    "# y_reshaped_float = tf.cast(y_reshaped, tf.float32)\n",
    "# loss = tf.reduce_mean(tf.square(y_reshaped_float - p_y_1))\n",
    "\n",
    "# # bool\n",
    "# predict = p_y_1 > 0.5\n",
    "# # [1,0,1,1,1,0,0,0]\n",
    "# correct_prediction = tf.equal(tf.cast(predict, tf.int64), y_reshaped)\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float64))\n",
    "# # [1,0,1,1,1,0,0,0]\n",
    "# correct_prediction = tf.equal(tf.cast(predict, tf.int64), y_reshaped)\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float64))\n",
    "\n",
    "# with tf.name_scope('train_op'):\n",
    "#     train_op = tf.train.AdamOptimizer(1e-3).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-45-c43b554010ec>:5: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From C:\\Users\\DYJ\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\layers\\core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "x = tf.placeholder(tf.float32, [None, X.shape[1]])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "hidden1 = tf.layers.dense(x, 400, activation=tf.nn.tanh)\n",
    "hidden2 = tf.layers.dense(hidden1, 400, activation=tf.nn.tanh)\n",
    "y_ = tf.layers.dense(hidden2, 1)\n",
    "p_y_1 = tf.nn.sigmoid(y_)\n",
    "y_reshaped = tf.reshape(y, (-1, 1))\n",
    "y_reshaped_float = tf.cast(y_reshaped, tf.float32)\n",
    "loss = tf.reduce_mean(tf.square(y_reshaped_float - p_y_1))\n",
    "predict = p_y_1 > 0.5\n",
    "correct_prediction = tf.equal(tf.cast(predict, tf.int64), y_reshaped)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float64))\n",
    "with tf.name_scope('train_op'):\n",
    "    train_op = tf.train.AdamOptimizer(1e-3).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DYJ\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "x = tf.placeholder(tf.float32, [None, X.shape[1]])\n",
    "# [None]\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "\n",
    "# (3072, 1)\n",
    "w = tf.get_variable('w', [x.get_shape()[-1], 1],\n",
    "                   initializer=tf.random_normal_initializer(0, 1))\n",
    "# (1, )\n",
    "b = tf.get_variable('b', [1],\n",
    "                   initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "# [None, 3072] * [3072, 1] = [None, 1]\n",
    "y_ = tf.matmul(x, w) + b\n",
    "\n",
    "# [None, 1]\n",
    "p_y_1 = tf.nn.sigmoid(y_)\n",
    "# [None, 1]\n",
    "y_reshaped = tf.reshape(y, (-1, 1))\n",
    "y_reshaped_float = tf.cast(y_reshaped, tf.float32)\n",
    "loss = tf.reduce_mean(tf.square(y_reshaped_float - p_y_1))\n",
    "\n",
    "# bool\n",
    "predict = p_y_1 > 0.5\n",
    "# [1,0,1,1,1,0,0,0]\n",
    "correct_prediction = tf.equal(tf.cast(predict, tf.int64), y_reshaped)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float64))\n",
    "\n",
    "with tf.name_scope('train_op'):\n",
    "    train_op = tf.train.AdamOptimizer(1e-3).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step: 500, loss: 0.15806, acc: 0.80000\n",
      "[Train] Step: 1000, loss: 0.08971, acc: 0.90000\n",
      "[Train] Step: 1500, loss: 0.16747, acc: 0.70000\n",
      "[Train] Step: 2000, loss: 0.09077, acc: 0.90000\n",
      "[Train] Step: 2500, loss: 0.10297, acc: 0.80000\n",
      "[Train] Step: 3000, loss: 0.30529, acc: 0.60000\n",
      "[Train] Step: 3500, loss: 0.02460, acc: 1.00000\n",
      "[Train] Step: 4000, loss: 0.00228, acc: 1.00000\n",
      "[Train] Step: 4500, loss: 0.19504, acc: 0.80000\n",
      "[Train] Step: 5000, loss: 0.09838, acc: 0.90000\n",
      "(1716, 307)\n",
      "(1716,)\n",
      "[Test ] Step: 5000, acc: 0.79000\n",
      "[Train] Step: 5500, loss: 0.00064, acc: 1.00000\n",
      "[Train] Step: 6000, loss: 0.00232, acc: 1.00000\n",
      "[Train] Step: 6500, loss: 0.00008, acc: 1.00000\n",
      "[Train] Step: 7000, loss: 0.00012, acc: 1.00000\n",
      "[Train] Step: 7500, loss: 0.03517, acc: 0.90000\n",
      "[Train] Step: 8000, loss: 0.00114, acc: 1.00000\n",
      "[Train] Step: 8500, loss: 0.00001, acc: 1.00000\n",
      "[Train] Step: 9000, loss: 0.00007, acc: 1.00000\n",
      "[Train] Step: 9500, loss: 0.00011, acc: 1.00000\n",
      "[Train] Step: 10000, loss: 0.00004, acc: 1.00000\n",
      "(1716, 307)\n",
      "(1716,)\n",
      "[Test ] Step: 10000, acc: 0.79714\n",
      "[Train] Step: 10500, loss: 0.00002, acc: 1.00000\n",
      "[Train] Step: 11000, loss: 0.00010, acc: 1.00000\n",
      "[Train] Step: 11500, loss: 0.01732, acc: 1.00000\n",
      "[Train] Step: 12000, loss: 0.01168, acc: 1.00000\n",
      "[Train] Step: 12500, loss: 0.00027, acc: 1.00000\n",
      "[Train] Step: 13000, loss: 0.00201, acc: 1.00000\n",
      "[Train] Step: 13500, loss: 0.00002, acc: 1.00000\n",
      "[Train] Step: 14000, loss: 0.00029, acc: 1.00000\n",
      "[Train] Step: 14500, loss: 0.00001, acc: 1.00000\n",
      "[Train] Step: 15000, loss: 0.00001, acc: 1.00000\n",
      "(1716, 307)\n",
      "(1716,)\n",
      "[Test ] Step: 15000, acc: 0.79857\n",
      "[Train] Step: 15500, loss: 0.00002, acc: 1.00000\n",
      "[Train] Step: 16000, loss: 0.00274, acc: 1.00000\n",
      "[Train] Step: 16500, loss: 0.00033, acc: 1.00000\n",
      "[Train] Step: 17000, loss: 0.00001, acc: 1.00000\n",
      "[Train] Step: 17500, loss: 0.00002, acc: 1.00000\n",
      "[Train] Step: 18000, loss: 0.00002, acc: 1.00000\n",
      "[Train] Step: 18500, loss: 0.00005, acc: 1.00000\n",
      "[Train] Step: 19000, loss: 0.10001, acc: 0.90000\n",
      "[Train] Step: 19500, loss: 0.00003, acc: 1.00000\n",
      "[Train] Step: 20000, loss: 0.00001, acc: 1.00000\n",
      "(1716, 307)\n",
      "(1716,)\n",
      "[Test ] Step: 20000, acc: 0.80286\n",
      "[Train] Step: 20500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 21000, loss: 0.10003, acc: 0.90000\n",
      "[Train] Step: 21500, loss: 0.00001, acc: 1.00000\n",
      "[Train] Step: 22000, loss: 0.00066, acc: 1.00000\n",
      "[Train] Step: 22500, loss: 0.00001, acc: 1.00000\n",
      "[Train] Step: 23000, loss: 0.00009, acc: 1.00000\n",
      "[Train] Step: 23500, loss: 0.00004, acc: 1.00000\n",
      "[Train] Step: 24000, loss: 0.00003, acc: 1.00000\n",
      "[Train] Step: 24500, loss: 0.00002, acc: 1.00000\n",
      "[Train] Step: 25000, loss: 0.00000, acc: 1.00000\n",
      "(1716, 307)\n",
      "(1716,)\n",
      "[Test ] Step: 25000, acc: 0.80143\n",
      "[Train] Step: 25500, loss: 0.00001, acc: 1.00000\n",
      "[Train] Step: 26000, loss: 0.00001, acc: 1.00000\n",
      "[Train] Step: 26500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 27000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 27500, loss: 0.00001, acc: 1.00000\n",
      "[Train] Step: 28000, loss: 0.00001, acc: 1.00000\n",
      "[Train] Step: 28500, loss: 0.00001, acc: 1.00000\n",
      "[Train] Step: 29000, loss: 0.00001, acc: 1.00000\n",
      "[Train] Step: 29500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 30000, loss: 0.06264, acc: 0.90000\n",
      "(1716, 307)\n",
      "(1716,)\n",
      "[Test ] Step: 30000, acc: 0.80857\n",
      "[Train] Step: 30500, loss: 0.00005, acc: 1.00000\n",
      "[Train] Step: 31000, loss: 0.00618, acc: 1.00000\n",
      "[Train] Step: 31500, loss: 0.00004, acc: 1.00000\n",
      "[Train] Step: 32000, loss: 0.00001, acc: 1.00000\n",
      "[Train] Step: 32500, loss: 0.00001, acc: 1.00000\n",
      "[Train] Step: 33000, loss: 0.00001, acc: 1.00000\n",
      "[Train] Step: 33500, loss: 0.00001, acc: 1.00000\n",
      "[Train] Step: 34000, loss: 0.00001, acc: 1.00000\n",
      "[Train] Step: 34500, loss: 0.00001, acc: 1.00000\n",
      "[Train] Step: 35000, loss: 0.00000, acc: 1.00000\n",
      "(1716, 307)\n",
      "(1716,)\n",
      "[Test ] Step: 35000, acc: 0.79429\n",
      "[Train] Step: 35500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 36000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 36500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 37000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 37500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 38000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 38500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 39000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 39500, loss: 0.00020, acc: 1.00000\n",
      "[Train] Step: 40000, loss: 0.06927, acc: 0.90000\n",
      "(1716, 307)\n",
      "(1716,)\n",
      "[Test ] Step: 40000, acc: 0.79571\n",
      "[Train] Step: 40500, loss: 0.00002, acc: 1.00000\n",
      "[Train] Step: 41000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 41500, loss: 0.00001, acc: 1.00000\n",
      "[Train] Step: 42000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 42500, loss: 0.00001, acc: 1.00000\n",
      "[Train] Step: 43000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 43500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 44000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 44500, loss: 0.00001, acc: 1.00000\n",
      "[Train] Step: 45000, loss: 0.00001, acc: 1.00000\n",
      "(1716, 307)\n",
      "(1716,)\n",
      "[Test ] Step: 45000, acc: 0.79000\n",
      "[Train] Step: 45500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 46000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 46500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 47000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 47500, loss: 0.08742, acc: 0.90000\n",
      "[Train] Step: 48000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 48500, loss: 0.00001, acc: 1.00000\n",
      "[Train] Step: 49000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 49500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 50000, loss: 0.00000, acc: 1.00000\n",
      "(1716, 307)\n",
      "(1716,)\n",
      "[Test ] Step: 50000, acc: 0.78857\n",
      "[Train] Step: 50500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 51000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 51500, loss: 0.00001, acc: 1.00000\n",
      "[Train] Step: 52000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 52500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 53000, loss: 0.00001, acc: 1.00000\n",
      "[Train] Step: 53500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 54000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 54500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 55000, loss: 0.00000, acc: 1.00000\n",
      "(1716, 307)\n",
      "(1716,)\n",
      "[Test ] Step: 55000, acc: 0.79286\n",
      "[Train] Step: 55500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 56000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 56500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 57000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 57500, loss: 0.05393, acc: 0.90000\n",
      "[Train] Step: 58000, loss: 0.06430, acc: 0.90000\n",
      "[Train] Step: 58500, loss: 0.00001, acc: 1.00000\n",
      "[Train] Step: 59000, loss: 0.10000, acc: 0.90000\n",
      "[Train] Step: 59500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 60000, loss: 0.00003, acc: 1.00000\n",
      "(1716, 307)\n",
      "(1716,)\n",
      "[Test ] Step: 60000, acc: 0.79000\n",
      "[Train] Step: 60500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 61000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 61500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 62000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 62500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 63000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 63500, loss: 0.00001, acc: 1.00000\n",
      "[Train] Step: 64000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 64500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 65000, loss: 0.00000, acc: 1.00000\n",
      "(1716, 307)\n",
      "(1716,)\n",
      "[Test ] Step: 65000, acc: 0.78714\n",
      "[Train] Step: 65500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 66000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 66500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 67000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 67500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 68000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 68500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 69000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 69500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 70000, loss: 0.00000, acc: 1.00000\n",
      "(1716, 307)\n",
      "(1716,)\n",
      "[Test ] Step: 70000, acc: 0.78714\n",
      "[Train] Step: 70500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 71000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 71500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 72000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 72500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 73000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 73500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 74000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 74500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 75000, loss: 0.00000, acc: 1.00000\n",
      "(1716, 307)\n",
      "(1716,)\n",
      "[Test ] Step: 75000, acc: 0.79143\n",
      "[Train] Step: 75500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 76000, loss: 0.00000, acc: 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step: 76500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 77000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 77500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 78000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 78500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 79000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 79500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 80000, loss: 0.00000, acc: 1.00000\n",
      "(1716, 307)\n",
      "(1716,)\n",
      "[Test ] Step: 80000, acc: 0.79143\n",
      "[Train] Step: 80500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 81000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 81500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 82000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 82500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 83000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 83500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 84000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 84500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 85000, loss: 0.00000, acc: 1.00000\n",
      "(1716, 307)\n",
      "(1716,)\n",
      "[Test ] Step: 85000, acc: 0.79000\n",
      "[Train] Step: 85500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 86000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 86500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 87000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 87500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 88000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 88500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 89000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 89500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 90000, loss: 0.00000, acc: 1.00000\n",
      "(1716, 307)\n",
      "(1716,)\n",
      "[Test ] Step: 90000, acc: 0.79143\n",
      "[Train] Step: 90500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 91000, loss: 0.10000, acc: 0.90000\n",
      "[Train] Step: 91500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 92000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 92500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 93000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 93500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 94000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 94500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 95000, loss: 0.00000, acc: 1.00000\n",
      "(1716, 307)\n",
      "(1716,)\n",
      "[Test ] Step: 95000, acc: 0.79143\n",
      "[Train] Step: 95500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 96000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 96500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 97000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 97500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 98000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 98500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 99000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 99500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 100000, loss: 0.00000, acc: 1.00000\n",
      "(1716, 307)\n",
      "(1716,)\n",
      "[Test ] Step: 100000, acc: 0.79143\n",
      "[Train] Step: 100500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 101000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 101500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 102000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 102500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 103000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 103500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 104000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 104500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 105000, loss: 0.00000, acc: 1.00000\n",
      "(1716, 307)\n",
      "(1716,)\n",
      "[Test ] Step: 105000, acc: 0.79143\n",
      "[Train] Step: 105500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 106000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 106500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 107000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 107500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 108000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 108500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 109000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 109500, loss: 0.10000, acc: 0.90000\n",
      "[Train] Step: 110000, loss: 0.00000, acc: 1.00000\n",
      "(1716, 307)\n",
      "(1716,)\n",
      "[Test ] Step: 110000, acc: 0.79000\n",
      "[Train] Step: 110500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 111000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 111500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 112000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 112500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 113000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 113500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 114000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 114500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 115000, loss: 0.00000, acc: 1.00000\n",
      "(1716, 307)\n",
      "(1716,)\n",
      "[Test ] Step: 115000, acc: 0.79000\n",
      "[Train] Step: 115500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 116000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 116500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 117000, loss: 0.10000, acc: 0.90000\n",
      "[Train] Step: 117500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 118000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 118500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 119000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 119500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 120000, loss: 0.00000, acc: 1.00000\n",
      "(1716, 307)\n",
      "(1716,)\n",
      "[Test ] Step: 120000, acc: 0.79000\n",
      "[Train] Step: 120500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 121000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 121500, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 122000, loss: 0.00000, acc: 1.00000\n",
      "[Train] Step: 122500, loss: 0.00000, acc: 1.00000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-c92f41d1240a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m             feed_dict={\n\u001b[0;32m     14\u001b[0m                 \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                 y: batch_labels})\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m500\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             print('[Train] Step: %d, loss: %4.5f, acc: %4.5f'\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1363\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "batch_size = 10\n",
    "train_steps = 1000000\n",
    "test_steps = 70\n",
    "\n",
    "# run 100k: 50.5%\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(train_steps):\n",
    "        batch_data, batch_labels = train_data.next_batch(batch_size)\n",
    "        loss_val, acc_val, _ = sess.run(\n",
    "            [loss, accuracy, train_op],\n",
    "            feed_dict={\n",
    "                x: batch_data,\n",
    "                y: batch_labels})\n",
    "        if (i+1) % 500 == 0:\n",
    "            print('[Train] Step: %d, loss: %4.5f, acc: %4.5f'\n",
    "                  % (i+1, loss_val, acc_val))\n",
    "        if (i+1) % 5000 == 0:\n",
    "            test_data = DiseaseData(False, False)\n",
    "            all_test_acc_val = []\n",
    "            for j in range(test_steps):\n",
    "                test_batch_data, test_batch_labels \\\n",
    "                    = test_data.next_batch(batch_size)\n",
    "                test_acc_val = sess.run(\n",
    "                    [accuracy],\n",
    "                    feed_dict = {\n",
    "                        x: test_batch_data, \n",
    "                        y: test_batch_labels\n",
    "                    })\n",
    "                all_test_acc_val.append(test_acc_val)\n",
    "            test_acc = np.mean(all_test_acc_val)\n",
    "            print('[Test ] Step: %d, acc: %4.5f'\n",
    "                  % (i+1, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
